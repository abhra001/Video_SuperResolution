{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38e60c3f",
        "outputId": "1296a589-d582-4b07-ef24-f7b590497d9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorboard_logger\n",
            "  Downloading tensorboard_logger-0.1.0-py2.py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from tensorboard_logger) (3.20.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tensorboard_logger) (1.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboard_logger) (1.22.4)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard_logger) (1.10.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard_logger) (8.4.0)\n",
            "Installing collected packages: tensorboard_logger\n",
            "Successfully installed tensorboard_logger-0.1.0\n"
          ]
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "import os\n",
        "import torch\n",
        "import argparse\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import time\n",
        "\n",
        "from math import log10\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "# from data_utils import DatasetFromH5_SFSR\n",
        "# from model import Net_SRCNN\n",
        "!pip install tensorboard_logger\n",
        "from tensorboard_logger import configure, log_value\n",
        "\n",
        "# from data_utils import DatasetFromH5_MFSR\n",
        "# from model import Net_VSRNet\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.init as init\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "id": "38e60c3f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b2fd3a7"
      },
      "source": [
        "## SRCNN"
      ],
      "id": "9b2fd3a7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3c3ee631"
      },
      "outputs": [],
      "source": [
        "class Net_SRCNN(nn.Module):\n",
        "    def __init__(self, upscale_factor):\n",
        "        super(Net_SRCNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1,  64, (9, 9), (1, 1), (4, 4))\n",
        "        self.conv2 = nn.Conv2d(64, 32, (5, 5), (1, 1), (2, 2))\n",
        "        self.conv3 = nn.Conv2d(32, 1,  (5, 5), (1, 1), (2, 2))\n",
        "        \n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = (self.conv3(x))\n",
        "        return x\n",
        "    \n",
        "    def _initialize_weights(self):\n",
        "        init.orthogonal_(self.conv1.weight, init.calculate_gain('relu'))\n",
        "        init.orthogonal_(self.conv2.weight, init.calculate_gain('relu'))\n",
        "        init.orthogonal_(self.conv3.weight)"
      ],
      "id": "3c3ee631"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3c765661"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data.dataset import Dataset\n",
        "import h5py\n",
        "\n",
        "class DatasetFromH5_MFSR(Dataset):\n",
        "    def __init__(self, image_dataset_dir, target_dataset_dir, upscale_factor, input_transform=None, target_transform=None):\n",
        "        super(DatasetFromH5_MFSR, self).__init__()\n",
        "        \n",
        "        image_h5_file = h5py.File(image_dataset_dir, 'r')\n",
        "        target_h5_file = h5py.File(target_dataset_dir, 'r')\n",
        "        image_dataset = image_h5_file['data']\n",
        "        target_dataset = target_h5_file['data']\n",
        "        \n",
        "        self.image_datasets = image_dataset\n",
        "        self.target_datasets = target_dataset\n",
        "        self.total_count = image_dataset.shape[0]\n",
        "        \n",
        "        self.input_transform = input_transform\n",
        "        self.target_transform = target_transform\n",
        "        \n",
        "    def __getitem__(self, index):        \n",
        "        image = self.image_datasets[index, :, :, :]\n",
        "        target = self.target_datasets[index, [2], :, :]\n",
        "        \n",
        "        image  = image.astype(np.float32)\n",
        "        target = target.astype(np.float32)\n",
        "        \n",
        "        #   Notice that image is the bicubic upscaled LR image patch, in float format, in range [0, 1]\n",
        "#        image = image / 255.0 \n",
        "        #   Notice that target is the HR image patch, in uint8 format, in range [0, 255]\n",
        "        target = target / 255.0\n",
        "        \n",
        "        image =  torch.from_numpy(image)\n",
        "        target = torch.from_numpy(target)\n",
        "\n",
        "        return image, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.total_count"
      ],
      "id": "3c765661"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFf6x0DDXRYo"
      },
      "outputs": [],
      "source": [
        "data_dir = \"./data\"\n",
        "\n",
        "downloads_dir = data_dir + '/downloads'\n",
        "datasets_dir = data_dir + '/datasets'\n",
        "models_dir = data_dir + '/models'\n",
        "pretrained_models = data_dir + '/pretrained_models'\n",
        "\n",
        "os.makedirs(downloads_dir, exist_ok=True)\n",
        "os.makedirs(datasets_dir, exist_ok=True)\n",
        "os.makedirs(models_dir, exist_ok=True)\n",
        "os.makedirs(pretrained_models, exist_ok=True)\n",
        "\n",
        "uf4_train_dir = datasets_dir + '/uf4_train'\n",
        "uf4_val_dir = datasets_dir + '/uf4_val'\n",
        "\n",
        "srrnet_train_lr = uf4_train_dir + '/srrnet_train_lr.h5'\n",
        "srrnet_train_hr = uf4_train_dir + '/srrnet_train_hr.h5'\n",
        "\n",
        "srrnet_val_lr = uf4_val_dir + '/srrnet_val_lr.h5'\n",
        "srrnet_val_hr = uf4_val_dir + '/srrnet_val_hr.h5'\n",
        "\n",
        "#!wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AACDZmHK7d2JQi0ADaoliM04a/uf_4/train/Data_CDVL_LR_Bic_MC_uf_4_ps_72_fn_5_tpn_225000.h5 -O srrnet_train_lr\n",
        "#!wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AACmrvoqkXXnZTXUFsWvNDCsa/uf_4/train/Data_CDVL_HR_uf_4_ps_72_fn_5_tpn_225000.h5 -O srrnet_train_hr\n",
        "\n",
        "#!wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AADJnJmRvFxmf7sxEk5G0Uuma/uf_4/val/Data_CDVL_LR_Bic_MC_uf_4_ps_72_fn_5_tpn_45000.h5 -O srrnet_val_lr\n",
        "#!wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AAChoVG4fLqdpsmSuq9wrEvFa/uf_4/val/Data_CDVL_HR_uf_4_ps_72_fn_5_tpn_45000.h5 -O srrnet_val_hr\n",
        "\n"
      ],
      "id": "zFf6x0DDXRYo"
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "tZfw7GgSSZSb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "395c2d9c-ef78-4ae5-f4a5-7ca17978079d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "id": "tZfw7GgSSZSb"
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/train_subset_12800.pkl', 'rb') as f:\n",
        "    subset_train = pickle.load(f)"
      ],
      "metadata": {
        "id": "yxNOa8_gO39f"
      },
      "execution_count": null,
      "outputs": [],
      "id": "yxNOa8_gO39f"
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/val_subset_12800.pkl', 'rb') as f:\n",
        "    subset_val = pickle.load(f)"
      ],
      "metadata": {
        "id": "pscx__FvTJkp"
      },
      "execution_count": null,
      "outputs": [],
      "id": "pscx__FvTJkp"
    },
    {
      "cell_type": "code",
      "source": [
        "upscale_factor = 4\n",
        "threads = 1\n",
        "batchSize = 256\n",
        "\n",
        "\n",
        "train_loader = DataLoader(dataset=subset_train, num_workers=threads, batch_size=batchSize, shuffle=False)\n",
        "val_loader = DataLoader(dataset=subset_val, num_workers=threads, batch_size=batchSize, shuffle=False)"
      ],
      "metadata": {
        "id": "A_8YXp3WnXrF"
      },
      "id": "A_8YXp3WnXrF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get the pretrained SRCNN"
      ],
      "metadata": {
        "id": "z9WRd1A80rWD"
      },
      "id": "z9WRd1A80rWD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef6b554c-8d3e-489c-ba0d-67281f296722",
        "id": "1-d52WyD0p_D"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-15 04:11:57--  https://www.dropbox.com/s/pd5b2ketm0oamhj/srcnn_x4.pth\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.81.18, 2620:100:6031:18::a27d:5112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.81.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/pd5b2ketm0oamhj/srcnn_x4.pth [following]\n",
            "--2023-05-15 04:11:57--  https://www.dropbox.com/s/raw/pd5b2ketm0oamhj/srcnn_x4.pth\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uce5e752fed8714dd5aaff06db4f.dl.dropboxusercontent.com/cd/0/inline/B8EAQTwkokBPp3rQby9XM02gF1FBErbPAkSV6EDNaQPshcwpMZpgOtVPVNGGlYPbC8ffr1MSE_oM1y5uMv7BgHGWCjDqhIeb8vBR0jdsPRFPbNBFlavfxC_FeFV9ckEMdUZ69mZfusAe5FaujoliJw9UAZFwX6ML5ps9QIxTd1MS7A/file# [following]\n",
            "--2023-05-15 04:11:58--  https://uce5e752fed8714dd5aaff06db4f.dl.dropboxusercontent.com/cd/0/inline/B8EAQTwkokBPp3rQby9XM02gF1FBErbPAkSV6EDNaQPshcwpMZpgOtVPVNGGlYPbC8ffr1MSE_oM1y5uMv7BgHGWCjDqhIeb8vBR0jdsPRFPbNBFlavfxC_FeFV9ckEMdUZ69mZfusAe5FaujoliJw9UAZFwX6ML5ps9QIxTd1MS7A/file\n",
            "Resolving uce5e752fed8714dd5aaff06db4f.dl.dropboxusercontent.com (uce5e752fed8714dd5aaff06db4f.dl.dropboxusercontent.com)... 162.125.81.15, 2620:100:6035:15::a27d:550f\n",
            "Connecting to uce5e752fed8714dd5aaff06db4f.dl.dropboxusercontent.com (uce5e752fed8714dd5aaff06db4f.dl.dropboxusercontent.com)|162.125.81.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/B8H6AwWZX_Ug7_XLyYdYFoff1slQueVoEiQG3AyjhvdCVBfHWHxskDrABHnyeuMQA1hlGlwVOX3mcYA2WQixYq8cqQYf28EXbdNzQhsK_aSAPaFOQsSz_Xm-Bjnt2-OMSMAih-DF33JZjugYTbFlV6x4npZ1c8a_c_S0lJel-7RvIAQORQWMy3xyDhhAj2erUXcrf2smenYtK-Zd4vsd5Q6pwh2VvO7IJrZDFnFF42HZK6J8JV8UblL-KurxKJJhWuD3ZqmbMg4707iH5QAWBBLitjbaFtElN-BIHtMHBPvaCqpzMs6sNFUZtRNF-D-vJFy7kwRwvglTMgdM2GV7cx1oDvoRyjo_45risYH55-91XtypwIh01oyc-LriFXM0JdWMzOZZD6dPq1LzuDx17ioX8Xt25wUMDCkfLR7TMsFGGg/file [following]\n",
            "--2023-05-15 04:11:58--  https://uce5e752fed8714dd5aaff06db4f.dl.dropboxusercontent.com/cd/0/inline2/B8H6AwWZX_Ug7_XLyYdYFoff1slQueVoEiQG3AyjhvdCVBfHWHxskDrABHnyeuMQA1hlGlwVOX3mcYA2WQixYq8cqQYf28EXbdNzQhsK_aSAPaFOQsSz_Xm-Bjnt2-OMSMAih-DF33JZjugYTbFlV6x4npZ1c8a_c_S0lJel-7RvIAQORQWMy3xyDhhAj2erUXcrf2smenYtK-Zd4vsd5Q6pwh2VvO7IJrZDFnFF42HZK6J8JV8UblL-KurxKJJhWuD3ZqmbMg4707iH5QAWBBLitjbaFtElN-BIHtMHBPvaCqpzMs6sNFUZtRNF-D-vJFy7kwRwvglTMgdM2GV7cx1oDvoRyjo_45risYH55-91XtypwIh01oyc-LriFXM0JdWMzOZZD6dPq1LzuDx17ioX8Xt25wUMDCkfLR7TMsFGGg/file\n",
            "Reusing existing connection to uce5e752fed8714dd5aaff06db4f.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 230278 (225K) [application/octet-stream]\n",
            "Saving to: ‘./data/pretrained_models/srcnn_model.pth’\n",
            "\n",
            "./data/pretrained_m 100%[===================>] 224.88K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2023-05-15 04:11:58 (43.3 MB/s) - ‘./data/pretrained_models/srcnn_model.pth’ saved [230278/230278]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.dropbox.com/s/pd5b2ketm0oamhj/srcnn_x4.pth -O {pretrained_models}/srcnn_model.pth"
      ],
      "id": "1-d52WyD0p_D"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWBS2iqJ0p_E"
      },
      "outputs": [],
      "source": [
        "upscale_factor = 4\n",
        "srcnn = Net_SRCNN(upscale_factor=upscale_factor)\n",
        "\n",
        "state_dict = srcnn.state_dict()\n",
        "for n, p in torch.load(pretrained_models+'/srcnn_model.pth', map_location=lambda storage, loc: storage).items():\n",
        "    if n in state_dict.keys():\n",
        "        state_dict[n].copy_(p)\n",
        "    else:\n",
        "        raise KeyError(n)\n",
        "\n",
        "torch.save(srcnn, pretrained_models+'/srcnn_model.pth')"
      ],
      "id": "HWBS2iqJ0p_E"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the VSRNet"
      ],
      "metadata": {
        "id": "nyMNCGnL00tK"
      },
      "id": "nyMNCGnL00tK"
    },
    {
      "cell_type": "code",
      "source": [
        "class Net_VSRNet(nn.Module):\n",
        "    def __init__(self, upscale_factor, srcnn_model):\n",
        "        super(Net_VSRNet, self).__init__()\n",
        "\n",
        "        self.conv1_f0 = nn.Conv2d(1,  64, (9, 9), (1, 1), (4, 4))\n",
        "        self.conv1_f1 = nn.Conv2d(1,  64, (9, 9), (1, 1), (4, 4))\n",
        "        self.conv1_f2 = nn.Conv2d(1,  64, (9, 9), (1, 1), (4, 4))\n",
        "        \n",
        "        \n",
        "        self.conv2_1 = nn.Conv2d(192, 32, (5, 5), (1, 1), (2, 2))\n",
        "        self.conv2_2 = nn.Conv2d(192, 32, (5, 5), (1, 1), (2, 2))\n",
        "        self.conv3 = nn.Conv2d(64, 1,  (5, 5), (1, 1), (2, 2))\n",
        "        \n",
        "        self.srcnn_model = srcnn_model\n",
        "        self.upscale_factor = upscale_factor\n",
        "        \n",
        "        self._initialize_weights()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        h10 = x[:,[0],:,:]\n",
        "        h11 = x[:,[1],:,:]\n",
        "        h12 = x[:,[2],:,:]\n",
        "        h13 = x[:,[3],:,:]\n",
        "        h14 = x[:,[4],:,:] \n",
        "\n",
        "        h10 = self.conv1_f0(h10)\n",
        "        h11 = self.conv1_f1(h11)\n",
        "        h12 = self.conv1_f2(h12)\n",
        "        h13 = self.conv1_f1(h13)\n",
        "        h14 = self.conv1_f0(h14) \n",
        "\n",
        "        x1 = F.relu(torch.cat((h10, h11, h12), 1))\n",
        "        x2 = F.relu(torch.cat((h12, h13, h14), 1))\n",
        "\n",
        "        x1 = self.conv2_1(x1)\n",
        "        x2 = self.conv2_2(x2)\n",
        "\n",
        "        x = F.relu(torch.cat((x1,x2),1))\n",
        "        x = (self.conv3(x))\n",
        "\n",
        "        return x\n",
        "    \n",
        "    def _initialize_weights(self):\n",
        "        \n",
        "        srcnn_model = torch.load(self.srcnn_model, map_location=lambda storage, loc: storage) # forcing to load to CPU       \n",
        "        \n",
        "        self.conv1_f0.weight.data = (srcnn_model.conv1.weight.data).clone()\n",
        "        self.conv1_f1.weight.data = (srcnn_model.conv1.weight.data).clone()\n",
        "        self.conv1_f2.weight.data = (srcnn_model.conv1.weight.data).clone()\n",
        "        \n",
        "        self.conv1_f0.bias.data = (srcnn_model.conv1.bias.data).clone()\n",
        "        self.conv1_f1.bias.data = (srcnn_model.conv1.bias.data).clone()\n",
        "        self.conv1_f2.bias.data = (srcnn_model.conv1.bias.data).clone()\n",
        "        \n",
        "        self.conv2_1.weight.data = torch.cat((srcnn_model.conv2.weight.data, \n",
        "                                            srcnn_model.conv2.weight.data, \n",
        "                                            srcnn_model.conv2.weight.data), 1).clone()/3.0\n",
        "\n",
        "        self.conv2_2.weight.data = torch.cat((srcnn_model.conv2.weight.data, \n",
        "                                            srcnn_model.conv2.weight.data, \n",
        "                                            srcnn_model.conv2.weight.data), 1).clone()/3.0\n",
        "        \n",
        "        self.conv2_1.bias.data = (srcnn_model.conv2.bias.data).clone()     \n",
        "        self.conv2_2.bias.data = (srcnn_model.conv2.bias.data).clone()\n",
        "\n",
        "        self.conv3.weight.data = torch.cat((srcnn_model.conv3.weight.data, \n",
        "                                            srcnn_model.conv3.weight.data), 1).clone()/2.0\n",
        "        \n",
        "        self.conv3.bias.data = (srcnn_model.conv3.bias.data).clone()"
      ],
      "metadata": {
        "id": "huh27ENvA3te"
      },
      "id": "huh27ENvA3te",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNxNuIVC0p_F"
      },
      "outputs": [],
      "source": [
        "model = Net_VSRNet(upscale_factor=upscale_factor, srcnn_model=pretrained_models+'/srcnn_model.pth')\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "    criterion = criterion.cuda()"
      ],
      "id": "mNxNuIVC0p_F"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5E2UvHTL1Amq"
      },
      "outputs": [],
      "source": [
        "lr = 0.001\n",
        "optimizer = optim.Adam([{'params': model.conv1_f0.parameters()},\n",
        "                        {'params': model.conv1_f1.parameters()},\n",
        "                        {'params': model.conv1_f2.parameters()},\n",
        "                        {'params': model.conv2_1.parameters()},\n",
        "                        {'params': model.conv2_2.parameters()},\n",
        "                        {'params': model.conv3.parameters(), 'lr': lr/10.0}\n",
        "                        ], lr=lr)"
      ],
      "id": "5E2UvHTL1Amq"
    },
    {
      "cell_type": "code",
      "source": [
        "configure(\"tensorBoardRuns/VSRNet-relu-mid-fusion-pretrain-sym-x4-batch-128-CDVL-225000x5x72x72-wd\")"
      ],
      "metadata": {
        "id": "mtt9OcFH1NLx"
      },
      "id": "mtt9OcFH1NLx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## DEFINE THE LOSS FUNCTION\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.models.vgg import vgg16\n",
        "#from torchvision.models.vgg import vgg19\n",
        "import cv2\n",
        "\n",
        "vgg = vgg16(pretrained=True)\n",
        "#vgg19 = vgg19(pretrained=True)\n",
        "\n",
        "loss_network = nn.Sequential(*list(vgg.features)[:31]).eval().cuda()\n",
        "#loss_network = nn.Sequential(*vgg19.features).eval()\n",
        "\n",
        "for param in loss_network.parameters():\n",
        "    param.requires_grad = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhxrfKe0u4Ze",
        "outputId": "d6a81895-2446-4c3c-a95f-392b28927896"
      },
      "id": "OhxrfKe0u4Ze",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:02<00:00, 218MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.set_grad_enabled(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUY-4fXB4bZQ",
        "outputId": "434d2273-adf2-4d06-9829-8f85f474d70b"
      },
      "id": "cUY-4fXB4bZQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.autograd.grad_mode.set_grad_enabled at 0x7f8d4a42bdf0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_loss_val(image,target): \n",
        "\n",
        "    loss = nn.MSELoss()\n",
        "    mse = loss(image,target)\n",
        " \n",
        "\n",
        "    image = torch.tensor(image,dtype=torch.float32)\n",
        "    target = torch.tensor(target,dtype=torch.float32)\n",
        "\n",
        "    image = image.repeat(3,1,1)\n",
        "    target = target.repeat(3,1,1)\n",
        "\n",
        "\n",
        "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "    target = target.reshape((1, target.shape[0], target.shape[1], target.shape[2]))\n",
        "\n",
        "\n",
        "    image_features = loss_network(image)\n",
        "    target_features = loss_network(target)\n",
        "\n",
        "    feature_loss =0.05*loss(image_features,target_features)  + 0.95*mse\n",
        "\n",
        "\n",
        "    return feature_loss\n",
        "\n",
        "\n",
        "def feature_loss_train(image,target): \n",
        "\n",
        "    loss = nn.MSELoss()\n",
        "    mse = loss(image,target)\n",
        "    \n",
        "    image = torch.tensor(image,dtype=torch.float32)\n",
        "    target = torch.tensor(target,dtype=torch.float32)\n",
        "\n",
        "    image = image.repeat(1,3,1,1)\n",
        "    target = target.repeat(1,3,1,1)\n",
        "\n",
        "    image_features = loss_network(image)\n",
        "    target_features = loss_network(target)\n",
        "\n",
        "    feature_loss = 0.05*loss(image_features,target_features)  + 0.95*mse\n",
        "\n",
        "    return feature_loss\n"
      ],
      "metadata": {
        "id": "q3X_n44QsZLK"
      },
      "id": "q3X_n44QsZLK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48z_dtoq1Amr"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train(epoch):\n",
        "    lr = 0.001\n",
        "    epoch_loss = 0\n",
        "    epoch_psnr = 0\n",
        "    start = time.time()\n",
        "    #   Step up learning rate decay\n",
        "    #   The network have 3 layers\n",
        "    lr = lr * (0.1 ** (epoch // (nEpochs // 4)))\n",
        "    \n",
        "    optimizer.param_groups[0]['lr'] = lr\n",
        "    optimizer.param_groups[1]['lr'] = lr\n",
        "    optimizer.param_groups[2]['lr'] = lr\n",
        "    optimizer.param_groups[3]['lr'] = lr\n",
        "    optimizer.param_groups[4]['lr'] = lr/10.0\n",
        "    \n",
        "\n",
        "    n = 0\n",
        "    for iteration, batch in enumerate(train_loader, 1):\n",
        "        if n >= 49:\n",
        "          break \n",
        "        n = n+1\n",
        "        image, target = Variable(batch[0]), Variable(batch[1])\n",
        "        if torch.cuda.is_available():\n",
        "            image = image.cuda()\n",
        "            target = target.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        #loss = criterion(model(image), target)\n",
        "        loss = feature_loss_train(model(image), target)\n",
        "        psnr = 10 * log10(1 / loss.data.item())\n",
        "        epoch_loss += loss.data.item()\n",
        "        epoch_psnr += psnr\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "    end = time.time()\n",
        "    print(\"===> Epoch {} Complete: lr: {}, Avg. Loss: {:.4f}, Avg.PSNR:  {:.4f} dB, Time: {:.4f}\".format(epoch, lr, epoch_loss / len(train_loader), epoch_psnr / len(train_loader), (end-start)))\n",
        "    \n",
        "    log_value('train_loss', epoch_loss / len(train_loader), epoch)\n",
        "    log_value('train_psnr', epoch_psnr / len(train_loader), epoch)"
      ],
      "id": "48z_dtoq1Amr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1GBHIoj1Amr"
      },
      "outputs": [],
      "source": [
        "def val(epoch):\n",
        "    #   Validation on CDVL val set\n",
        "    lr = 0.001\n",
        "    avg_psnr = 0\n",
        "    avg_mse = 0\n",
        "    frame_count = 0\n",
        "    start = time.time()\n",
        "    n = 0\n",
        "    for batch in val_loader:\n",
        "        if n >= 49:\n",
        "          break \n",
        "        n = n+1\n",
        "        image, target = Variable(batch[0]), Variable(batch[1])\n",
        "        if torch.cuda.is_available():\n",
        "            image = image.cuda()\n",
        "            target = target.cuda()\n",
        "\n",
        "        prediction = model(image)\n",
        "\n",
        "        for i in range(0, image.shape[0]):\n",
        "            #mse = criterion(prediction[i], target[i])\n",
        "            mse = feature_loss_val(prediction[i], target[i])\n",
        "            psnr = 10 * log10(1 / mse.data.item())\n",
        "            avg_psnr += psnr\n",
        "            avg_mse  += mse.data.item()\n",
        "            frame_count += 1\n",
        "\n",
        "    end = time.time()\n",
        "    print(\"===> Epoch {} Validation CDVL: Avg. Loss: {:.4f}, Avg.PSNR:  {:.4f} dB, Time: {:.4f}\".format(epoch, avg_mse / frame_count, avg_psnr / frame_count, (end-start)))\n",
        "\n",
        "    log_value('val_loss', avg_mse / frame_count, epoch)\n",
        "    log_value('val_psnr', avg_psnr / frame_count, epoch)"
      ],
      "id": "b1GBHIoj1Amr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEDjfLqW1Amr"
      },
      "outputs": [],
      "source": [
        "def checkpoint(epoch):\n",
        "    if epoch%10 == 0:\n",
        "        if not os.path.exists(\"epochs_VSRNet\"):\n",
        "            os.makedirs(\"epochs_VSRNet\")\n",
        "        model_out_path = \"epochs_VSRNet/\" + \"model_epoch_{}.pth\".format(epoch)\n",
        "        torch.save(model, model_out_path)\n",
        "        print(\"Checkpoint saved to {}\".format(model_out_path))"
      ],
      "id": "bEDjfLqW1Amr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2db1418b-3bb1-4b95-d956-76702127bb32",
        "id": "iQpSMdlg1Ams"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-0241bd36608d>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  image = torch.tensor(image,dtype=torch.float32)\n",
            "<ipython-input-17-0241bd36608d>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  target = torch.tensor(target,dtype=torch.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===> Epoch 0 Validation CDVL: Avg. Loss: 0.0027, Avg.PSNR:  31.2922 dB, Time: 102.3706\n",
            "Checkpoint saved to epochs_VSRNet/model_epoch_0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-0241bd36608d>:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  image = torch.tensor(image,dtype=torch.float32)\n",
            "<ipython-input-17-0241bd36608d>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  target = torch.tensor(target,dtype=torch.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===> Epoch 1 Complete: lr: 0.001, Avg. Loss: 0.0002, Avg.PSNR:  1.4234 dB, Time: 65.4345\n",
            "===> Epoch 1 Validation CDVL: Avg. Loss: 0.0033, Avg.PSNR:  28.2987 dB, Time: 98.5894\n",
            "===> Epoch 2 Complete: lr: 0.0001, Avg. Loss: 0.0001, Avg.PSNR:  1.5628 dB, Time: 64.6984\n",
            "===> Epoch 2 Validation CDVL: Avg. Loss: 0.0032, Avg.PSNR:  29.0244 dB, Time: 98.3582\n",
            "===> Epoch 3 Complete: lr: 0.0001, Avg. Loss: 0.0001, Avg.PSNR:  1.5788 dB, Time: 64.6724\n",
            "===> Epoch 3 Validation CDVL: Avg. Loss: 0.0030, Avg.PSNR:  30.1373 dB, Time: 98.2604\n",
            "===> Epoch 4 Complete: lr: 1.0000000000000003e-05, Avg. Loss: 0.0001, Avg.PSNR:  1.5918 dB, Time: 64.6091\n",
            "===> Epoch 4 Validation CDVL: Avg. Loss: 0.0030, Avg.PSNR:  30.0836 dB, Time: 98.3722\n",
            "===> Epoch 5 Complete: lr: 1.0000000000000003e-05, Avg. Loss: 0.0001, Avg.PSNR:  1.5925 dB, Time: 64.6427\n",
            "===> Epoch 5 Validation CDVL: Avg. Loss: 0.0030, Avg.PSNR:  29.9725 dB, Time: 98.3883\n",
            "===> Epoch 6 Complete: lr: 1.0000000000000002e-06, Avg. Loss: 0.0001, Avg.PSNR:  1.5931 dB, Time: 64.6389\n",
            "===> Epoch 6 Validation CDVL: Avg. Loss: 0.0030, Avg.PSNR:  29.9455 dB, Time: 98.4003\n",
            "===> Epoch 7 Complete: lr: 1.0000000000000002e-06, Avg. Loss: 0.0001, Avg.PSNR:  1.5946 dB, Time: 64.6079\n",
            "===> Epoch 7 Validation CDVL: Avg. Loss: 0.0030, Avg.PSNR:  30.1153 dB, Time: 98.4445\n",
            "===> Epoch 8 Complete: lr: 1.0000000000000002e-07, Avg. Loss: 0.0001, Avg.PSNR:  1.5969 dB, Time: 64.6427\n",
            "===> Epoch 8 Validation CDVL: Avg. Loss: 0.0029, Avg.PSNR:  30.2856 dB, Time: 98.4301\n",
            "===> Epoch 9 Complete: lr: 1.0000000000000002e-07, Avg. Loss: 0.0001, Avg.PSNR:  1.5985 dB, Time: 64.6608\n",
            "===> Epoch 9 Validation CDVL: Avg. Loss: 0.0029, Avg.PSNR:  30.3439 dB, Time: 98.4638\n",
            "===> Epoch 10 Complete: lr: 1.0000000000000004e-08, Avg. Loss: 0.0001, Avg.PSNR:  1.5995 dB, Time: 64.6926\n",
            "===> Epoch 10 Validation CDVL: Avg. Loss: 0.0029, Avg.PSNR:  30.3663 dB, Time: 98.4765\n",
            "Checkpoint saved to epochs_VSRNet/model_epoch_10.pth\n"
          ]
        }
      ],
      "source": [
        "nEpochs = 10\n",
        "lr = 0.001\n",
        "\n",
        "val(0)\n",
        "checkpoint(0)\n",
        "for epoch in range(1, nEpochs + 1):\n",
        "    train(epoch)\n",
        "    val(epoch)\n",
        "    checkpoint(epoch)"
      ],
      "id": "iQpSMdlg1Ams"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n0PZzBtfv6qc"
      },
      "id": "n0PZzBtfv6qc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's test with a video!"
      ],
      "metadata": {
        "id": "LykHAvh-uy4J"
      },
      "id": "LykHAvh-uy4J"
    },
    {
      "cell_type": "code",
      "source": [
        "uf4_test_dir = datasets_dir + '/uf4_test'\n",
        "\n",
        "vsrnet_test_lr = uf4_test_dir + '/vsrnet_test_lr.h5'\n",
        "vsrnet_test_hr = uf4_test_dir + '/vsrnet_test_hr.h5'\n",
        "\n",
        "\n",
        "#!wget https://www.dropbox.com/s/q3evjn917cwv9ax/scene_40.h5?dl=0 -O vsrnet_test_lr\n",
        "#!wget https://www.dropbox.com/s/lxm30agjddg72xe/scene_40.h5?dl=0 -O vsrnet_test_hr\n",
        "\n",
        "\n",
        "#!wget https://www.dropbox.com/s/5khbznl4expk2b3/scene_37.h5?dl=0 -O vsrnet_test_lr\n",
        "#!wget https://www.dropbox.com/s/csq8bjzp0d3rb3h/scene_37.h5?dl=0 -O vsrnet_test_hr\n",
        "\n",
        "\n",
        "\n",
        "!wget https://www.dropbox.com/s/qtacz4akqng2gxy/scene_23.h5?dl=0 -O vsrnet_test_lr\n",
        "!wget https://www.dropbox.com/s/4vx8252vxivpgmo/scene_23.h5?dl=0 -O vsrnet_test_hr\n",
        "\n",
        "\n",
        "#!wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AAADzBQ7iA492oQ26ag67ZsKa/uf_4/test/LR_Bic_MC/scene_30.h5 -O vsrnet_test_lr\n",
        "#!wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AADSka3PgSR5EuCt9ByugfY6a/uf_4/test/HR/scene_30.h5 -O vsrnet_test_hr\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKIjgWgjuyT2",
        "outputId": "2f299439-8e63-46c2-cd89-f3dfd119732b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-13 16:46:57--  https://www.dropbox.com/s/qtacz4akqng2gxy/scene_23.h5?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:6016:18::a27d:112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/qtacz4akqng2gxy/scene_23.h5 [following]\n",
            "--2023-05-13 16:46:57--  https://www.dropbox.com/s/raw/qtacz4akqng2gxy/scene_23.h5\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucc05cdd8ae9018562e198f889bf.dl.dropboxusercontent.com/cd/0/inline/B797XPVzShsOZv9hNN2NfUDNm_A91Rj0gTel06OLst2wnSSPPrplQhkahxu1S5QAF8ExLlBoYGXfLNpX1YsQAfN_ikdiZO0aO6HL5LPGDGgppgf5HyrppXlB9dqZTNkJrEFrbFLzmnOCRYmv_Uq0FsgjEIDTHhkDCZvNvXs6E7pUjQ/file# [following]\n",
            "--2023-05-13 16:46:58--  https://ucc05cdd8ae9018562e198f889bf.dl.dropboxusercontent.com/cd/0/inline/B797XPVzShsOZv9hNN2NfUDNm_A91Rj0gTel06OLst2wnSSPPrplQhkahxu1S5QAF8ExLlBoYGXfLNpX1YsQAfN_ikdiZO0aO6HL5LPGDGgppgf5HyrppXlB9dqZTNkJrEFrbFLzmnOCRYmv_Uq0FsgjEIDTHhkDCZvNvXs6E7pUjQ/file\n",
            "Resolving ucc05cdd8ae9018562e198f889bf.dl.dropboxusercontent.com (ucc05cdd8ae9018562e198f889bf.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f\n",
            "Connecting to ucc05cdd8ae9018562e198f889bf.dl.dropboxusercontent.com (ucc05cdd8ae9018562e198f889bf.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/B7_s_wecs8w7uSoGCHxozhQRAK8Nl-rJVmG8B7JCD33C29cFETUSvsi1uz2wUTvZ4Ic-fzqwS38hcd8ff0WgGvjvrf2sNB-PkeWJQ96oBCW0FSZNcqrSsmNwKTW7TovGZlbh_WYX0B2E8L2XAWWSGIFwBDO261gvqiGafhDa-EPCS795clyoyin2wJB5Y3ftmFqNtziBjPVeejK_brZOQhJlHuhYQ6WgLKhcQgThPXNf4UB6lY7RDdfT_8gEta5jSMv3hvnVvsNwuQqvLdIbXQbdjDw2PdMku2gjrVqKKX4CPFqz9_jTBlkOgmUk9Akcbae3N4OTFkwh4EsIGU2051Fq2vUcJXqfx4aixuNu7j7UkPjYwFIwc8qEwLdAsrnQZmSxIl7IkARric6tdlX98dOf1cZNAE_jRN5DsPdf6z66jQ/file [following]\n",
            "--2023-05-13 16:46:58--  https://ucc05cdd8ae9018562e198f889bf.dl.dropboxusercontent.com/cd/0/inline2/B7_s_wecs8w7uSoGCHxozhQRAK8Nl-rJVmG8B7JCD33C29cFETUSvsi1uz2wUTvZ4Ic-fzqwS38hcd8ff0WgGvjvrf2sNB-PkeWJQ96oBCW0FSZNcqrSsmNwKTW7TovGZlbh_WYX0B2E8L2XAWWSGIFwBDO261gvqiGafhDa-EPCS795clyoyin2wJB5Y3ftmFqNtziBjPVeejK_brZOQhJlHuhYQ6WgLKhcQgThPXNf4UB6lY7RDdfT_8gEta5jSMv3hvnVvsNwuQqvLdIbXQbdjDw2PdMku2gjrVqKKX4CPFqz9_jTBlkOgmUk9Akcbae3N4OTFkwh4EsIGU2051Fq2vUcJXqfx4aixuNu7j7UkPjYwFIwc8qEwLdAsrnQZmSxIl7IkARric6tdlX98dOf1cZNAE_jRN5DsPdf6z66jQ/file\n",
            "Reusing existing connection to ucc05cdd8ae9018562e198f889bf.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 580613056 (554M) [application/octet-stream]\n",
            "Saving to: ‘vsrnet_test_lr’\n",
            "\n",
            "vsrnet_test_lr      100%[===================>] 553.71M   161MB/s    in 3.4s    \n",
            "\n",
            "2023-05-13 16:47:02 (161 MB/s) - ‘vsrnet_test_lr’ saved [580613056/580613056]\n",
            "\n",
            "--2023-05-13 16:47:02--  https://www.dropbox.com/s/4vx8252vxivpgmo/scene_23.h5?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:6016:18::a27d:112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/4vx8252vxivpgmo/scene_23.h5 [following]\n",
            "--2023-05-13 16:47:03--  https://www.dropbox.com/s/raw/4vx8252vxivpgmo/scene_23.h5\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucad4b77bcf0aac78702302ac5fb.dl.dropboxusercontent.com/cd/0/inline/B78-LOHfx3-R_S-8Frzv097csBVQ_W29K1K9A1bCCAst4XUz5Iej9a14ujOcdG9S84te9Q7MFe75haXycHvHfN90yuK1CwCiqoi3ZRnP5OPBhBEeMq4BHUSUisXUHfMsBpDjvnPokgZ9pgNQzYwd4E465gFV2fGV1V7In1Givg03jw/file# [following]\n",
            "--2023-05-13 16:47:03--  https://ucad4b77bcf0aac78702302ac5fb.dl.dropboxusercontent.com/cd/0/inline/B78-LOHfx3-R_S-8Frzv097csBVQ_W29K1K9A1bCCAst4XUz5Iej9a14ujOcdG9S84te9Q7MFe75haXycHvHfN90yuK1CwCiqoi3ZRnP5OPBhBEeMq4BHUSUisXUHfMsBpDjvnPokgZ9pgNQzYwd4E465gFV2fGV1V7In1Givg03jw/file\n",
            "Resolving ucad4b77bcf0aac78702302ac5fb.dl.dropboxusercontent.com (ucad4b77bcf0aac78702302ac5fb.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f\n",
            "Connecting to ucad4b77bcf0aac78702302ac5fb.dl.dropboxusercontent.com (ucad4b77bcf0aac78702302ac5fb.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/B7-7reixh7GBkkRb2NM7J5NHKH9zo4hhJ3X3uBa5DX_dE8q60-K07f1f6S0MxA02pqOmrR8WmBwTqKX1mPsvhbY6P1pOirqUI7tZMhbBfHAC1HBi3HqIGFXtRbDz04CnMqrH-P2s3VndmjjI7N5MGddeSNYJ2jwNE6AwZt2BOJ0YkHcOxhlNaOeaP6N2odbWNkNygWN6S-IJF3p4_L2U4sfUWVgCyCUf0SI2oIqqlUe0bqrEsk86Tq8vdUHMZqIL3fjbtCSHqPud8Ww9dnvW2Mx1ihBQAeP4EIF8yNec7A9wWrYiMZymULdLANiH_vmFB-3FSap-O4YOBW-ALzWXzVke59-AzeDjSmryu9B47R8Q20-DmFvPQ8wP9XQi4uqS4tJxmj95-hbXol28NdMJc6apyXALvb8ruVXzKVo611rpcw/file [following]\n",
            "--2023-05-13 16:47:04--  https://ucad4b77bcf0aac78702302ac5fb.dl.dropboxusercontent.com/cd/0/inline2/B7-7reixh7GBkkRb2NM7J5NHKH9zo4hhJ3X3uBa5DX_dE8q60-K07f1f6S0MxA02pqOmrR8WmBwTqKX1mPsvhbY6P1pOirqUI7tZMhbBfHAC1HBi3HqIGFXtRbDz04CnMqrH-P2s3VndmjjI7N5MGddeSNYJ2jwNE6AwZt2BOJ0YkHcOxhlNaOeaP6N2odbWNkNygWN6S-IJF3p4_L2U4sfUWVgCyCUf0SI2oIqqlUe0bqrEsk86Tq8vdUHMZqIL3fjbtCSHqPud8Ww9dnvW2Mx1ihBQAeP4EIF8yNec7A9wWrYiMZymULdLANiH_vmFB-3FSap-O4YOBW-ALzWXzVke59-AzeDjSmryu9B47R8Q20-DmFvPQ8wP9XQi4uqS4tJxmj95-hbXol28NdMJc6apyXALvb8ruVXzKVo611rpcw/file\n",
            "Reusing existing connection to ucad4b77bcf0aac78702302ac5fb.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29035456 (28M) [application/octet-stream]\n",
            "Saving to: ‘vsrnet_test_hr’\n",
            "\n",
            "vsrnet_test_hr      100%[===================>]  27.69M   178MB/s    in 0.2s    \n",
            "\n",
            "2023-05-13 16:47:04 (178 MB/s) - ‘vsrnet_test_hr’ saved [29035456/29035456]\n",
            "\n"
          ]
        }
      ],
      "id": "mKIjgWgjuyT2"
    },
    {
      "cell_type": "code",
      "source": [
        "path_LR_Bic_MC = './vsrnet_test_hr'\n",
        "path_HR = './vsrnet_test_hr'\n",
        "videos_h5_name = ['scene_23.h5']\n",
        "videos_h5_name.sort()"
      ],
      "metadata": {
        "id": "O3oQP1rrvc3z"
      },
      "execution_count": null,
      "outputs": [],
      "id": "O3oQP1rrvc3z"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Gcsux3vwZJq"
      },
      "outputs": [],
      "source": [
        "h5_len = len(videos_h5_name)\n",
        "model_PSNR   = np.zeros(h5_len)\n",
        "model_SSIM   = np.zeros(h5_len)\n",
        "bicubic_PSNR = np.zeros(h5_len)\n",
        "bicubic_SSIM = np.zeros(h5_len)\n",
        "model_time   = np.zeros(h5_len)"
      ],
      "id": "2Gcsux3vwZJq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8U3KtNhwawy"
      },
      "outputs": [],
      "source": [
        "out_path = './'\n",
        "if not os.path.exists(out_path):\n",
        "    os.makedirs(out_path)"
      ],
      "id": "J8U3KtNhwawy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iA009Ixi2RPw"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "import math\n",
        "\n",
        "def psnr(img1, img2):\n",
        "    mse = numpy.mean( (img1 - img2) ** 2 )\n",
        "    if mse == 0:\n",
        "        return 100\n",
        "    PIXEL_MAX = 255.0\n",
        "    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))"
      ],
      "id": "iA009Ixi2RPw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSlXCgjh2dRH"
      },
      "outputs": [],
      "source": [
        "from scipy.ndimage import gaussian_filter\n",
        "\n",
        "from numpy.lib.stride_tricks import as_strided as ast\n",
        "\n",
        "\"\"\"\n",
        "Hat tip: http://stackoverflow.com/a/5078155/1828289\n",
        "\"\"\"\n",
        "def block_view(A, block=(3, 3)):\n",
        "    \"\"\"Provide a 2D block view to 2D array. No error checking made.\n",
        "    Therefore meaningful (as implemented) only for blocks strictly\n",
        "    compatible with the shape of A.\"\"\"\n",
        "    # simple shape and strides computations may seem at first strange\n",
        "    # unless one is able to recognize the 'tuple additions' involved ;-)\n",
        "    shape = (A.shape[0]// block[0], A.shape[1]// block[1])+ block\n",
        "    strides = (block[0]* A.strides[0], block[1]* A.strides[1])+ A.strides\n",
        "    return ast(A, shape= shape, strides= strides)\n",
        "\n",
        "\n",
        "def ssim(img1, img2, C1=0.01**2, C2=0.03**2):\n",
        "\n",
        "    bimg1 = block_view(img1, (4,4))\n",
        "    bimg2 = block_view(img2, (4,4))\n",
        "    s1  = numpy.sum(bimg1, (-1, -2))\n",
        "    s2  = numpy.sum(bimg2, (-1, -2))\n",
        "    ss  = numpy.sum(bimg1*bimg1, (-1, -2)) + numpy.sum(bimg2*bimg2, (-1, -2))\n",
        "    s12 = numpy.sum(bimg1*bimg2, (-1, -2))\n",
        "\n",
        "    vari = ss - s1*s1 - s2*s2\n",
        "    covar = s12 - s1*s2\n",
        "\n",
        "    ssim_map =  (2*s1*s2 + C1) * (2*covar + C2) / ((s1*s1 + s2*s2 + C1) * (vari + C2))\n",
        "    return numpy.mean(ssim_map)\n",
        "\n",
        "# FIXME there seems to be a problem with this code\n",
        "def ssim_exact(img1, img2, sd=1.5, C1=0.01**2, C2=0.03**2):\n",
        "\n",
        "    mu1 = gaussian_filter(img1, sd)\n",
        "    mu2 = gaussian_filter(img2, sd)\n",
        "    mu1_sq = mu1 * mu1\n",
        "    mu2_sq = mu2 * mu2\n",
        "    mu1_mu2 = mu1 * mu2\n",
        "    sigma1_sq = gaussian_filter(img1 * img1, sd) - mu1_sq\n",
        "    sigma2_sq = gaussian_filter(img2 * img2, sd) - mu2_sq\n",
        "    sigma12 = gaussian_filter(img1 * img2, sd) - mu1_mu2\n",
        "\n",
        "    ssim_num = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2))\n",
        "\n",
        "    ssim_den = ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
        "\n",
        "    ssim_map = ssim_num / ssim_den\n",
        "    return numpy.mean(ssim_map)"
      ],
      "id": "wSlXCgjh2dRH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1L_fRCrVwhHv",
        "outputId": "35c6c449-2f54-47cf-9a4f-997a67fb6309"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14/14 [00:12<00:00,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===> Test on Video Idx: 0 Complete: Model PSNR: 37.4952 dB, Model SSIM: 0.9969 , Bicubic PSNR:  40.3283 dB, Bicubic SSIM: 0.9994 , Average time: 689.7565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import cv2\n",
        "\n",
        "video_idx = 0\n",
        "#   Read h5 file\n",
        "LR_Bic_MC_h5_file = h5py.File('./vsrnet_test_lr', 'r')\n",
        "LR_Bic_MC_h5_data = LR_Bic_MC_h5_file['data']\n",
        "HR_h5_file = h5py.File('./vsrnet_test_hr', 'r')\n",
        "HR_h5_data = HR_h5_file['data']\n",
        "    \n",
        "# load to memory\n",
        "HR_h5_data = HR_h5_data[()]#.value\n",
        "LR_Bic_MC_h5_data = LR_Bic_MC_h5_data[()]#.value\n",
        "    \n",
        "# transpose to correct order\n",
        "HR_h5_data = np.transpose(HR_h5_data, (3, 2, 1, 0))\n",
        "LR_Bic_MC_h5_data = np.transpose(LR_Bic_MC_h5_data, (3, 2, 1, 0))\n",
        "    \n",
        "frame_number = LR_Bic_MC_h5_data.shape[0]\n",
        "\n",
        "IS_REAL_TIME = False\n",
        "\n",
        "video_name = 'scene_23_SRCNN+vgg'\n",
        "    \n",
        "if not IS_REAL_TIME:\n",
        "    fps = 30\n",
        "    size = (LR_Bic_MC_h5_data.shape[3], LR_Bic_MC_h5_data.shape[2])\n",
        "    output_name = out_path + video_name.split('.')[0] + '.avi'\n",
        "    videoWriter = cv2.VideoWriter(output_name, cv2.VideoWriter_fourcc('M','J','P','G'), fps, size)\n",
        "#            videoWriter = cv2.VideoWriter(output_name, cv2.VideoWriter_fourcc(*'XVID'), fps, size)\n",
        "        \n",
        "#   Prepare to save PSNR and SSIM of the current video\n",
        "#   Each value corresponding to one test frame\n",
        "model_PSNR_cur   = np.zeros(frame_number)\n",
        "model_SSIM_cur   = np.zeros(frame_number)\n",
        "bicubic_PSNR_cur = np.zeros(frame_number)\n",
        "bicubic_SSIM_cur = np.zeros(frame_number)\n",
        "model_time_cur   = np.zeros(frame_number)\n",
        "    \n",
        "for idx in tqdm(range(0, frame_number)):\n",
        "    img_HR = HR_h5_data[idx, 0, :, :] #2D\n",
        "    img_LR_Bic_MC = LR_Bic_MC_h5_data[idx, :, :, :] #3D 5x1080x1920\n",
        "    \n",
        "    # Reshape to 4D\n",
        "    img_LR_Bic_MC = img_LR_Bic_MC.reshape((1, img_LR_Bic_MC.shape[0], img_LR_Bic_MC.shape[1], img_LR_Bic_MC.shape[2]))\n",
        "    \n",
        "    img_LR_Bic_MC = img_LR_Bic_MC.astype(np.float32)\n",
        "\n",
        "    img_LR_Bic_MC =  torch.from_numpy(img_LR_Bic_MC)\n",
        "                        \n",
        "    if torch.cuda.is_available():\n",
        "        img_LR_Bic_MC = img_LR_Bic_MC.cuda()\n",
        "\n",
        "    start = time.time()\n",
        "    if img_LR_Bic_MC.sum() != 0:\n",
        "        img_HR_net = model(img_LR_Bic_MC)\n",
        "\n",
        "    else:\n",
        "        img_HR_net = img_LR_Bic_MC[:,2,:,:]\n",
        "        img_HR_net = img_HR_net.reshape((1, 1, img_HR.shape[0], img_HR.shape[1])) # reshape to 1x1x1080x1920\n",
        "        \n",
        "    end = time.time() # measure the computation time\n",
        "    \n",
        "    img_HR_net = img_HR_net.cpu()\n",
        "    img_HR_net = img_HR_net.data[0].numpy()\n",
        "    img_HR_net *= 255.0\n",
        "    img_HR_net = img_HR_net.clip(0, 255)\n",
        "    img_HR_net = img_HR_net.astype(np.uint8)\n",
        "    \n",
        "    img_LR_Bic_MC = img_LR_Bic_MC.cpu()\n",
        "    img_LR_Bic = img_LR_Bic_MC[:, 2, :, :] # center frame\n",
        "    img_LR_Bic = img_LR_Bic.data[0].numpy()\n",
        "    img_LR_Bic *= 255.0\n",
        "    img_LR_Bic = img_LR_Bic.clip(0, 255)\n",
        "    img_LR_Bic = img_LR_Bic.astype(np.uint8)\n",
        "    \n",
        "    img_HR = img_HR.reshape((1, img_HR.shape[0], img_HR.shape[1]))\n",
        "    img_LR_Bic = img_LR_Bic.reshape((1, img_LR_Bic.shape[0], img_LR_Bic.shape[1]))\n",
        "\n",
        "    \n",
        "    model_PSNR_cur[idx]   = psnr((img_HR).reshape(img_HR.shape[1], img_HR.shape[2]).astype(int), (img_HR_net).reshape(img_HR_net.shape[1], img_HR_net.shape[2]).astype(int))\n",
        "    model_SSIM_cur[idx]   = ssim((img_HR).reshape(img_HR.shape[1], img_HR.shape[2]).astype(int), (img_HR_net).reshape(img_HR_net.shape[1], img_HR_net.shape[2]).astype(int))\n",
        "    bicubic_PSNR_cur[idx] = psnr((img_HR).reshape(img_HR.shape[1], img_HR.shape[2]).astype(int), (img_LR_Bic).reshape(img_LR_Bic.shape[1], img_LR_Bic.shape[2]).astype(int))\n",
        "    bicubic_SSIM_cur[idx] = ssim((img_HR).reshape(img_HR.shape[1], img_HR.shape[2]).astype(int), (img_LR_Bic).reshape(img_LR_Bic.shape[1], img_LR_Bic.shape[2]).astype(int))\n",
        "    model_time_cur[idx]   = (end-start)\n",
        "\n",
        "    # Repeat to 3 channels to save and display\n",
        "    img_HR_net = np.repeat(img_HR_net, 3, axis=0)\n",
        "    img_HR_net = np.transpose(img_HR_net, (1, 2, 0))\n",
        "\n",
        "    if IS_REAL_TIME:\n",
        "        plt.imshow(img_HR_net, cmap = 'gray')\n",
        "        plt.show()\n",
        "\n",
        "#                cv2.imshow('LR Video ', img_LR_Bic)\n",
        "#                cv2.imshow('SR Video ', img_HR_net)\n",
        "#                cv2.waitKey(DELAY_TIME)\n",
        "    else:\n",
        "        # save video\n",
        "        videoWriter.write(img_HR_net)\n",
        "    \n",
        "# Done video writing\n",
        "videoWriter.release()\n",
        "\n",
        "# Save PSNR and SSIM\n",
        "# Exclude PSNR = 100 cases (caused by black frames)\n",
        "cal_flag = (model_PSNR_cur != 100)\n",
        "model_PSNR[video_idx]   = np.mean(model_PSNR_cur[cal_flag])\n",
        "model_SSIM[video_idx]   = np.mean(model_SSIM_cur[cal_flag])\n",
        "bicubic_PSNR[video_idx] = np.mean(bicubic_PSNR_cur[cal_flag])\n",
        "bicubic_SSIM[video_idx] = np.mean(bicubic_SSIM_cur[cal_flag])\n",
        "model_time[video_idx]   = np.mean(model_time_cur[cal_flag])\n",
        "\n",
        "print(\"===> Test on Video Idx: \" + str(video_idx) +\" Complete: Model PSNR: {:.4f} dB, Model SSIM: {:.4f} , Bicubic PSNR:  {:.4f} dB, Bicubic SSIM: {:.4f} , Average time: {:.4f}\"\n",
        "  .format(model_PSNR[video_idx], model_SSIM[video_idx], bicubic_PSNR[video_idx], bicubic_SSIM[video_idx], model_time[video_idx]*1000))\n",
        "video_idx += 1"
      ],
      "id": "1L_fRCrVwhHv"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sP3KU2cPHkcQ"
      },
      "id": "sP3KU2cPHkcQ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}