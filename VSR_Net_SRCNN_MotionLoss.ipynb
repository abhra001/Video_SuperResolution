{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38e60c3f",
        "outputId": "2ec3708b-76a6-4397-b533-2e33d6837e8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorboard_logger in /usr/local/lib/python3.10/dist-packages (0.1.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from tensorboard_logger) (3.20.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tensorboard_logger) (1.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboard_logger) (1.22.4)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard_logger) (1.10.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard_logger) (8.4.0)\n"
          ]
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "import os\n",
        "import torch\n",
        "import argparse\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import time\n",
        "\n",
        "from math import log10\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "# from data_utils import DatasetFromH5_SFSR\n",
        "# from model import Net_SRCNN\n",
        "!pip install tensorboard_logger\n",
        "from tensorboard_logger import configure, log_value\n",
        "\n",
        "# from data_utils import DatasetFromH5_MFSR\n",
        "# from model import Net_VSRNet\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.init as init\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "id": "38e60c3f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b2fd3a7"
      },
      "source": [
        "## SRCNN"
      ],
      "id": "9b2fd3a7"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3c3ee631"
      },
      "outputs": [],
      "source": [
        "class Net_SRCNN(nn.Module):\n",
        "    def __init__(self, upscale_factor):\n",
        "        super(Net_SRCNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1,  64, (9, 9), (1, 1), (4, 4))\n",
        "        self.conv2 = nn.Conv2d(64, 32, (5, 5), (1, 1), (2, 2))\n",
        "        self.conv3 = nn.Conv2d(32, 1,  (5, 5), (1, 1), (2, 2))\n",
        "        \n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = (self.conv3(x))\n",
        "        return x\n",
        "    \n",
        "    def _initialize_weights(self):\n",
        "        init.orthogonal_(self.conv1.weight, init.calculate_gain('relu'))\n",
        "        init.orthogonal_(self.conv2.weight, init.calculate_gain('relu'))\n",
        "        init.orthogonal_(self.conv3.weight)"
      ],
      "id": "3c3ee631"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3c765661"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data.dataset import Dataset\n",
        "import h5py\n",
        "\n",
        "class DatasetFromH5_MFSR(Dataset):\n",
        "    def __init__(self, image_dataset_dir, target_dataset_dir, upscale_factor, input_transform=None, target_transform=None):\n",
        "        super(DatasetFromH5_MFSR, self).__init__()\n",
        "        \n",
        "        image_h5_file = h5py.File(image_dataset_dir, 'r')\n",
        "        target_h5_file = h5py.File(target_dataset_dir, 'r')\n",
        "        image_dataset = image_h5_file['data']\n",
        "        target_dataset = target_h5_file['data']\n",
        "        \n",
        "        self.image_datasets = image_dataset\n",
        "        self.target_datasets = target_dataset\n",
        "        self.total_count = image_dataset.shape[0]\n",
        "        \n",
        "        self.input_transform = input_transform\n",
        "        self.target_transform = target_transform\n",
        "        \n",
        "    def __getitem__(self, index):        \n",
        "        image = self.image_datasets[index, :, :, :]\n",
        "        target = self.target_datasets[index, [2], :, :]\n",
        "        \n",
        "        image  = image.astype(np.float32)\n",
        "        target = target.astype(np.float32)\n",
        "        \n",
        "        #   Notice that image is the bicubic upscaled LR image patch, in float format, in range [0, 1]\n",
        "#        image = image / 255.0 \n",
        "        #   Notice that target is the HR image patch, in uint8 format, in range [0, 255]\n",
        "        target = target / 255.0\n",
        "        \n",
        "        image =  torch.from_numpy(image)\n",
        "        target = torch.from_numpy(target)\n",
        "\n",
        "        return image, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.total_count"
      ],
      "id": "3c765661"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zFf6x0DDXRYo"
      },
      "outputs": [],
      "source": [
        "data_dir = \"./data\"\n",
        "\n",
        "downloads_dir = data_dir + '/downloads'\n",
        "datasets_dir = data_dir + '/datasets'\n",
        "models_dir = data_dir + '/models'\n",
        "pretrained_models = data_dir + '/pretrained_models'\n",
        "\n",
        "os.makedirs(downloads_dir, exist_ok=True)\n",
        "os.makedirs(datasets_dir, exist_ok=True)\n",
        "os.makedirs(models_dir, exist_ok=True)\n",
        "os.makedirs(pretrained_models, exist_ok=True)\n",
        "\n",
        "uf4_train_dir = datasets_dir + '/uf4_train'\n",
        "uf4_val_dir = datasets_dir + '/uf4_val'\n",
        "\n",
        "srrnet_train_lr = uf4_train_dir + '/srrnet_train_lr.h5'\n",
        "srrnet_train_hr = uf4_train_dir + '/srrnet_train_hr.h5'\n",
        "\n",
        "srrnet_val_lr = uf4_val_dir + '/srrnet_val_lr.h5'\n",
        "srrnet_val_hr = uf4_val_dir + '/srrnet_val_hr.h5'\n",
        "\n",
        "#!wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AACDZmHK7d2JQi0ADaoliM04a/uf_4/train/Data_CDVL_LR_Bic_MC_uf_4_ps_72_fn_5_tpn_225000.h5 -O srrnet_train_lr\n",
        "#!wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AACmrvoqkXXnZTXUFsWvNDCsa/uf_4/train/Data_CDVL_HR_uf_4_ps_72_fn_5_tpn_225000.h5 -O srrnet_train_hr\n",
        "\n",
        "#!wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AADJnJmRvFxmf7sxEk5G0Uuma/uf_4/val/Data_CDVL_LR_Bic_MC_uf_4_ps_72_fn_5_tpn_45000.h5 -O srrnet_val_lr\n",
        "#!wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AAChoVG4fLqdpsmSuq9wrEvFa/uf_4/val/Data_CDVL_HR_uf_4_ps_72_fn_5_tpn_45000.h5 -O srrnet_val_hr\n",
        "\n"
      ],
      "id": "zFf6x0DDXRYo"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZfw7GgSSZSb",
        "outputId": "1e5ed92e-5512-4829-e26d-a8e2be02d7ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "tZfw7GgSSZSb"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yxNOa8_gO39f"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/Computer_Vision/train_subset_12800.pkl', 'rb') as f:\n",
        "    subset_train = pickle.load(f)"
      ],
      "id": "yxNOa8_gO39f"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pscx__FvTJkp"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/Computer_Vision/val_subset_12800.pkl', 'rb') as f:\n",
        "    subset_val = pickle.load(f)"
      ],
      "id": "pscx__FvTJkp"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "A_8YXp3WnXrF"
      },
      "outputs": [],
      "source": [
        "upscale_factor = 4\n",
        "threads = 1\n",
        "batchSize = 256\n",
        "\n",
        "\n",
        "train_loader = DataLoader(dataset=subset_train, num_workers=threads, batch_size=batchSize, shuffle=False)\n",
        "val_loader = DataLoader(dataset=subset_val, num_workers=threads, batch_size=batchSize, shuffle=False)"
      ],
      "id": "A_8YXp3WnXrF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9WRd1A80rWD"
      },
      "source": [
        "## Get the pretrained SRCNN"
      ],
      "id": "z9WRd1A80rWD"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-d52WyD0p_D",
        "outputId": "9a0af018-6364-40fe-f07f-26bbac29e5ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-14 23:03:41--  https://www.dropbox.com/s/pd5b2ketm0oamhj/srcnn_x4.pth\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.81.18, 2620:100:6031:18::a27d:5112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.81.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/pd5b2ketm0oamhj/srcnn_x4.pth [following]\n",
            "--2023-05-14 23:03:41--  https://www.dropbox.com/s/raw/pd5b2ketm0oamhj/srcnn_x4.pth\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uccb873599992d9f8c92bdcb5060.dl.dropboxusercontent.com/cd/0/inline/B8EZN22Q2LS8iOm4pwqWnMNhfvzj_Hd-TpVL-y4ptM_DBEM0db66Hl3P7dT7fBTn7ZGFh24WOVIYCuYD432WE3netObKcOyc2kBcp5lb9rfLf0RuAsZgyaLbUZqIz64DUbbA6_InQdNK6uInY0zKMKNT8w25DwJpfru5f27ozjw8Ig/file# [following]\n",
            "--2023-05-14 23:03:41--  https://uccb873599992d9f8c92bdcb5060.dl.dropboxusercontent.com/cd/0/inline/B8EZN22Q2LS8iOm4pwqWnMNhfvzj_Hd-TpVL-y4ptM_DBEM0db66Hl3P7dT7fBTn7ZGFh24WOVIYCuYD432WE3netObKcOyc2kBcp5lb9rfLf0RuAsZgyaLbUZqIz64DUbbA6_InQdNK6uInY0zKMKNT8w25DwJpfru5f27ozjw8Ig/file\n",
            "Resolving uccb873599992d9f8c92bdcb5060.dl.dropboxusercontent.com (uccb873599992d9f8c92bdcb5060.dl.dropboxusercontent.com)... 162.125.81.15, 2620:100:6031:15::a27d:510f\n",
            "Connecting to uccb873599992d9f8c92bdcb5060.dl.dropboxusercontent.com (uccb873599992d9f8c92bdcb5060.dl.dropboxusercontent.com)|162.125.81.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/B8HXmAJC_oJPYffPKlznk-h3Gp78T15f1yRu9pLwCoggUCgJKT-rOPIz3piGEHRV0YZPDkbwmrz4d126zP14KCZx5VzesMECrc5_oXGlGHIgUODu0bc9ACv9F36xPOtOUSwjLPjUfuPJag7pnRBRDFSQHhI26Po5jyiznJujSY_vQydg2Aearj3a5-fzjoF7K27oF55xRhRPn6OE0R6dtVs3KDXRr2mPdQnyMbfA_bq6BPkQwmH6Kl70gIMkuKXJn_1aEQ84fKhx_e9y5LVSlzQyBN0c0A8fwFhmdi1g3igK4JYilY8nnQ4iIdf4gcxKvgmcw_FCOGf7yoOD9Ab9J-i4L4wkrGnTJ_Cyf-QzqPDlZp2w0umz6KtsQUWv_vlr9pjFncJHypWc6wxy6TtMQZh7bu8DD-kzWpMvsKkY2j1BLg/file [following]\n",
            "--2023-05-14 23:03:42--  https://uccb873599992d9f8c92bdcb5060.dl.dropboxusercontent.com/cd/0/inline2/B8HXmAJC_oJPYffPKlznk-h3Gp78T15f1yRu9pLwCoggUCgJKT-rOPIz3piGEHRV0YZPDkbwmrz4d126zP14KCZx5VzesMECrc5_oXGlGHIgUODu0bc9ACv9F36xPOtOUSwjLPjUfuPJag7pnRBRDFSQHhI26Po5jyiznJujSY_vQydg2Aearj3a5-fzjoF7K27oF55xRhRPn6OE0R6dtVs3KDXRr2mPdQnyMbfA_bq6BPkQwmH6Kl70gIMkuKXJn_1aEQ84fKhx_e9y5LVSlzQyBN0c0A8fwFhmdi1g3igK4JYilY8nnQ4iIdf4gcxKvgmcw_FCOGf7yoOD9Ab9J-i4L4wkrGnTJ_Cyf-QzqPDlZp2w0umz6KtsQUWv_vlr9pjFncJHypWc6wxy6TtMQZh7bu8DD-kzWpMvsKkY2j1BLg/file\n",
            "Reusing existing connection to uccb873599992d9f8c92bdcb5060.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 230278 (225K) [application/octet-stream]\n",
            "Saving to: ‘./data/pretrained_models/srcnn_model.pth’\n",
            "\n",
            "./data/pretrained_m 100%[===================>] 224.88K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2023-05-14 23:03:42 (32.1 MB/s) - ‘./data/pretrained_models/srcnn_model.pth’ saved [230278/230278]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.dropbox.com/s/pd5b2ketm0oamhj/srcnn_x4.pth -O {pretrained_models}/srcnn_model.pth"
      ],
      "id": "1-d52WyD0p_D"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "HWBS2iqJ0p_E"
      },
      "outputs": [],
      "source": [
        "upscale_factor = 4\n",
        "srcnn = Net_SRCNN(upscale_factor=upscale_factor)\n",
        "\n",
        "state_dict = srcnn.state_dict()\n",
        "for n, p in torch.load(pretrained_models+'/srcnn_model.pth', map_location=lambda storage, loc: storage).items():\n",
        "    if n in state_dict.keys():\n",
        "        state_dict[n].copy_(p)\n",
        "    else:\n",
        "        raise KeyError(n)\n",
        "\n",
        "torch.save(srcnn, pretrained_models+'/srcnn_model.pth')"
      ],
      "id": "HWBS2iqJ0p_E"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyMNCGnL00tK"
      },
      "source": [
        "Define the VSRNet"
      ],
      "id": "nyMNCGnL00tK"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "huh27ENvA3te"
      },
      "outputs": [],
      "source": [
        "class Net_VSRNet(nn.Module):\n",
        "    def __init__(self, upscale_factor, srcnn_model):\n",
        "        super(Net_VSRNet, self).__init__()\n",
        "\n",
        "        self.conv1_f0 = nn.Conv2d(1,  64, (9, 9), (1, 1), (4, 4))\n",
        "        self.conv1_f1 = nn.Conv2d(1,  64, (9, 9), (1, 1), (4, 4))\n",
        "        self.conv1_f2 = nn.Conv2d(1,  64, (9, 9), (1, 1), (4, 4))\n",
        "        \n",
        "        \n",
        "        self.conv2_1 = nn.Conv2d(192, 32, (5, 5), (1, 1), (2, 2))\n",
        "        self.conv2_2 = nn.Conv2d(192, 32, (5, 5), (1, 1), (2, 2))\n",
        "        self.conv3 = nn.Conv2d(64, 1,  (5, 5), (1, 1), (2, 2))\n",
        "        \n",
        "        self.srcnn_model = srcnn_model\n",
        "        self.upscale_factor = upscale_factor\n",
        "        \n",
        "        self._initialize_weights()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        h10 = x[:,[0],:,:]\n",
        "        h11 = x[:,[1],:,:]\n",
        "        h12 = x[:,[2],:,:]\n",
        "        h13 = x[:,[3],:,:]\n",
        "        h14 = x[:,[4],:,:] \n",
        "\n",
        "        h10 = self.conv1_f0(h10)\n",
        "        h11 = self.conv1_f1(h11)\n",
        "        h12 = self.conv1_f2(h12)\n",
        "        h13 = self.conv1_f1(h13)\n",
        "        h14 = self.conv1_f0(h14) \n",
        "\n",
        "        x1 = F.relu(torch.cat((h10, h11, h12), 1))\n",
        "        x2 = F.relu(torch.cat((h12, h13, h14), 1))\n",
        "\n",
        "        x1 = self.conv2_1(x1)\n",
        "        x2 = self.conv2_2(x2)\n",
        "\n",
        "        x = F.relu(torch.cat((x1,x2),1))\n",
        "        x = (self.conv3(x))\n",
        "\n",
        "        return x\n",
        "    \n",
        "    def _initialize_weights(self):\n",
        "        \n",
        "        srcnn_model = torch.load(self.srcnn_model, map_location=lambda storage, loc: storage) # forcing to load to CPU       \n",
        "        \n",
        "        self.conv1_f0.weight.data = (srcnn_model.conv1.weight.data).clone()\n",
        "        self.conv1_f1.weight.data = (srcnn_model.conv1.weight.data).clone()\n",
        "        self.conv1_f2.weight.data = (srcnn_model.conv1.weight.data).clone()\n",
        "        \n",
        "        self.conv1_f0.bias.data = (srcnn_model.conv1.bias.data).clone()\n",
        "        self.conv1_f1.bias.data = (srcnn_model.conv1.bias.data).clone()\n",
        "        self.conv1_f2.bias.data = (srcnn_model.conv1.bias.data).clone()\n",
        "        \n",
        "        self.conv2_1.weight.data = torch.cat((srcnn_model.conv2.weight.data, \n",
        "                                            srcnn_model.conv2.weight.data, \n",
        "                                            srcnn_model.conv2.weight.data), 1).clone()/3.0\n",
        "\n",
        "        self.conv2_2.weight.data = torch.cat((srcnn_model.conv2.weight.data, \n",
        "                                            srcnn_model.conv2.weight.data, \n",
        "                                            srcnn_model.conv2.weight.data), 1).clone()/3.0\n",
        "        \n",
        "        self.conv2_1.bias.data = (srcnn_model.conv2.bias.data).clone()     \n",
        "        self.conv2_2.bias.data = (srcnn_model.conv2.bias.data).clone()\n",
        "\n",
        "        self.conv3.weight.data = torch.cat((srcnn_model.conv3.weight.data, \n",
        "                                            srcnn_model.conv3.weight.data), 1).clone()/2.0\n",
        "        \n",
        "        self.conv3.bias.data = (srcnn_model.conv3.bias.data).clone()"
      ],
      "id": "huh27ENvA3te"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "mNxNuIVC0p_F"
      },
      "outputs": [],
      "source": [
        "model = Net_VSRNet(upscale_factor=upscale_factor, srcnn_model=pretrained_models+'/srcnn_model.pth')\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "    criterion = criterion.cuda()"
      ],
      "id": "mNxNuIVC0p_F"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5E2UvHTL1Amq"
      },
      "outputs": [],
      "source": [
        "lr = 0.001\n",
        "optimizer = optim.Adam([{'params': model.conv1_f0.parameters()},\n",
        "                        {'params': model.conv1_f1.parameters()},\n",
        "                        {'params': model.conv1_f2.parameters()},\n",
        "                        {'params': model.conv2_1.parameters()},\n",
        "                        {'params': model.conv2_2.parameters()},\n",
        "                        {'params': model.conv3.parameters(), 'lr': lr/10.0}\n",
        "                        ], lr=lr)"
      ],
      "id": "5E2UvHTL1Amq"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "mtt9OcFH1NLx"
      },
      "outputs": [],
      "source": [
        "configure(\"tensorBoardRuns/VSRNet-relu-mid-fusion-pretrain-sym-x4-batch-128-CDVL-225000x5x72x72-wd\")"
      ],
      "id": "mtt9OcFH1NLx"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "MOludGgODul4"
      },
      "outputs": [],
      "source": [
        "from scipy import ndimage \n",
        "torch.set_grad_enabled(True)  # Context-manager \n",
        "\n",
        "sobelx = [[1, 0, -1], [2, 0, -2], [1, 0, -1]]\n",
        "sobely = [[1, 2, 1], [0, 0, 0], [-1, -2, -1]]        \n",
        "depth = 1\n",
        "channels = 1\n",
        "\n",
        "sobelx_kernel = torch.tensor(sobelx, dtype=torch.float32, requires_grad=True).unsqueeze(0).expand(depth, channels, 3, 3)\n",
        "sobely_kernel = torch.tensor(sobely, dtype=torch.float32, requires_grad=True).unsqueeze(0).expand(depth, channels, 3, 3)\n",
        "\n",
        "sobelz = [[[1, 2, 1], [2, 4, 2], [1, 2, 1]],[[0, 0, 0], [0, 0, 0], [0, 0, 0]],[[-1, -2, -1], [-2, -4, -2], [-1, -2, -1]]] \n",
        "sobelz_kernel = torch.tensor(sobelz, dtype=torch.float32, requires_grad=True).unsqueeze(0)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    sobelx_kernel = sobelx_kernel.cuda()\n",
        "    sobely_kernel = sobely_kernel.cuda()\n",
        "    sobelz_kernel = sobelz_kernel.cuda()\n",
        "\n",
        "def motion_loss(input, predicted, target):\n",
        "\n",
        "    mse = 0\n",
        "    batch_size=256\n",
        "\n",
        "    for i in range(batch_size):\n",
        "\n",
        "        input[i,2,:,:] = predicted[i,:,:,:]\n",
        "\n",
        "        frames_inp = input[i,1:4,:,:] \n",
        "        frames_tar = frames_inp.clone()\n",
        "        frames_tar[i,:,:] = target[i,:,:,:] \n",
        "\n",
        "        x=input[i,2,:,:].unsqueeze(0).unsqueeze(0)\n",
        "        x=x.reshape((x.shape[1],1,x.shape[2],x.shape[3]))\n",
        "        t=target[i,0,:,:].unsqueeze(0).unsqueeze(0)\n",
        "        t=t.reshape((t.shape[1],1,t.shape[2],t.shape[3]))\n",
        "        # print(frames_inp.shape)\n",
        "        \n",
        "        # dx = torch.tensor(ndimage.sobel(input[:,2,:,:], 0), requires_grad=True)  # horizontal derivative\n",
        "        # dy = torch.tensor(ndimage.sobel(input[:,2,:,:], 1), requires_grad=True)\n",
        "        dx = F.conv2d(x, sobelx_kernel, stride=1, padding=1).squeeze(0)\n",
        "        dy = F.conv2d(x, sobely_kernel, stride=1, padding=1).squeeze(0)\n",
        "        # dz = ndimage.sobel(frames_inp, 2)[1,:,:]\n",
        "        dz = F.conv2d(frames_inp, sobelz_kernel, stride=1, padding=1)\n",
        "        # print(dz.shape)\n",
        "\n",
        "        # dxt = torch.tensor(ndimage.sobel(target[:,0,:,:], 0), requires_grad=True)  # horizontal derivative\n",
        "        # dyt = torch.tensor(ndimage.sobel(target[:,0,:,:], 1), requires_grad=True)\n",
        "        dxt = F.conv2d(t, sobelx_kernel, stride=1, padding=1).squeeze(0)\n",
        "        dyt = F.conv2d(t, sobely_kernel, stride=1, padding=1).squeeze(0)\n",
        "        # dzt = ndimage.sobel(frames_tar, 2)[1,:,:]\n",
        "        dzt = F.conv2d(frames_tar, sobelz_kernel, stride=1, padding=1)\n",
        "\n",
        "        # dxdt = torch.tensor(np.divide(dx, dz, out=np.zeros_like(dx), where=dz!=0))\n",
        "        # dydt = torch.tensor(np.divide(dy, dz, out=np.zeros_like(dy), where=dz!=0))\n",
        "\n",
        "        mask = (dz != 0)\n",
        "        dxdt = torch.full_like(dx, fill_value=float(0))\n",
        "        dxdt[mask] = dx[mask] / dz[mask]\n",
        "        dydt = torch.full_like(dy, fill_value=float(0))\n",
        "        dydt[mask] = dy[mask] / dz[mask]\n",
        "\n",
        "        # dxtdz = torch.tensor(np.divide(dxt, dzt, out=np.zeros_like(dxt), where=dzt!=0))\n",
        "        # dytdz = torch.tensor(np.divide(dyt, dzt, out=np.zeros_like(dyt), where=dzt!=0))\n",
        "\n",
        "        mask = (dzt != 0)\n",
        "        dxtdz = torch.full_like(dxt, fill_value=float(0))\n",
        "        dxtdz[mask] = dxt[mask] / dzt[mask]\n",
        "        dytdz = torch.full_like(dyt, fill_value=float(0))\n",
        "        dytdz[mask] = dyt[mask] / dzt[mask]\n",
        "\n",
        "        dxdt = (dxdt - torch.min(dxdt)) / (torch.max(dxdt) - torch.min(dxdt))\n",
        "        dxtdz = (dxtdz - torch.min(dxtdz)) / (torch.max(dxtdz) - torch.min(dxtdz))\n",
        "        dydt = (dydt - torch.min(dydt)) / (torch.max(dydt) - torch.min(dydt))\n",
        "        dytdz = (dytdz - torch.min(dytdz)) / (torch.max(dytdz) - torch.min(dytdz))\n",
        "\n",
        "        mse += 0.8*F.mse_loss(input[i,2,:,:], target[i,0,:,:])+0.1*F.mse_loss(dxdt, dxtdz)+0.1*F.mse_loss(dydt, dytdz)\n",
        "\n",
        "    return mse\n"
      ],
      "id": "MOludGgODul4"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "48z_dtoq1Amr"
      },
      "outputs": [],
      "source": [
        "def train(epoch):\n",
        "    lr = 0.001\n",
        "    epoch_loss = 0\n",
        "    epoch_psnr = 0\n",
        "    start = time.time()\n",
        "    #   Step up learning rate decay\n",
        "    #   The network have 3 layers\n",
        "    lr = lr * (0.1 ** (epoch // (nEpochs // 4)))\n",
        "    \n",
        "    optimizer.param_groups[0]['lr'] = lr\n",
        "    optimizer.param_groups[1]['lr'] = lr\n",
        "    optimizer.param_groups[2]['lr'] = lr\n",
        "    optimizer.param_groups[3]['lr'] = lr\n",
        "    optimizer.param_groups[4]['lr'] = lr/10.0\n",
        "    \n",
        "\n",
        "    n = 0\n",
        "    for iteration, batch in enumerate(train_loader, 1):\n",
        "        if n >= 49:\n",
        "          break \n",
        "        n = n+1\n",
        "        image, target = Variable(batch[0]), Variable(batch[1])\n",
        "        if torch.cuda.is_available():\n",
        "            image = image.cuda()\n",
        "            target = target.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        #loss = criterion(model(image), target)\n",
        "        loss = motion_loss(image,model(image), target)\n",
        "        psnr = 10 * log10(1 / loss.data.item())\n",
        "        epoch_loss += loss.data.item()\n",
        "        epoch_psnr += psnr\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "    end = time.time()\n",
        "    print(\"===> Epoch {} Complete: lr: {}, Avg. Loss: {:.4f}, Avg.PSNR:  {:.4f} dB, Time: {:.4f}\".format(epoch, lr, epoch_loss / len(train_loader), epoch_psnr / len(train_loader), (end-start)))\n",
        "    \n",
        "    log_value('train_loss', epoch_loss / len(train_loader), epoch)\n",
        "    log_value('train_psnr', epoch_psnr / len(train_loader), epoch)"
      ],
      "id": "48z_dtoq1Amr"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "b1GBHIoj1Amr"
      },
      "outputs": [],
      "source": [
        "def val(epoch):\n",
        "    #   Validation on CDVL val set\n",
        "    lr = 0.001\n",
        "    avg_psnr = 0\n",
        "    avg_mse = 0\n",
        "    frame_count = 0\n",
        "    start = time.time()\n",
        "    n = 0\n",
        "    for batch in val_loader:\n",
        "        if n >= 49:\n",
        "          break \n",
        "        n = n+1\n",
        "        image, target = Variable(batch[0]), Variable(batch[1])\n",
        "        if torch.cuda.is_available():\n",
        "            image = image.cuda()\n",
        "            target = target.cuda()\n",
        "\n",
        "        prediction = model(image)\n",
        "\n",
        "        for i in range(0, image.shape[0]):\n",
        "            mse = criterion(prediction[i], target[i])\n",
        "            # mse = motion_loss(image[],prediction[i], target[i])\n",
        "            psnr = 10 * log10(1 / mse.data.item())\n",
        "            avg_psnr += psnr\n",
        "            avg_mse  += mse.data.item()\n",
        "            frame_count += 1\n",
        "\n",
        "    end = time.time()\n",
        "    print(\"===> Epoch {} Validation CDVL: Avg. Loss: {:.4f}, Avg.PSNR:  {:.4f} dB, Time: {:.4f}\".format(epoch, avg_mse / frame_count, avg_psnr / frame_count, (end-start)))\n",
        "\n",
        "    log_value('val_loss', avg_mse / frame_count, epoch)\n",
        "    log_value('val_psnr', avg_psnr / frame_count, epoch)"
      ],
      "id": "b1GBHIoj1Amr"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "bEDjfLqW1Amr"
      },
      "outputs": [],
      "source": [
        "def checkpoint(epoch):\n",
        "    if epoch%10 == 0:\n",
        "        if not os.path.exists(\"epochs_VSRNet\"):\n",
        "            os.makedirs(\"epochs_VSRNet\")\n",
        "        model_out_path = \"epochs_VSRNet/\" + \"model_epoch_{}.pth\".format(epoch)\n",
        "        torch.save(model, model_out_path)\n",
        "        print(\"Checkpoint saved to {}\".format(model_out_path))"
      ],
      "id": "bEDjfLqW1Amr"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "id": "iQpSMdlg1Ams",
        "outputId": "a380b06d-459d-4a50-e579-0b366952d07c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-cf676b7cf4de>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#checkpoint(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnEpochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mcheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-a61d02a2419a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mepoch_psnr\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpsnr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [72, 72]], which is output 0 of AsStridedBackward0, is at version 3; expected version 2 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True)."
          ]
        }
      ],
      "source": [
        "nEpochs = 5\n",
        "lr = 0.001\n",
        "\n",
        "#val(0)\n",
        "#checkpoint(0)\n",
        "for epoch in range(1, nEpochs + 1):\n",
        "    train(epoch)\n",
        "    val(epoch)\n",
        "    checkpoint(epoch)"
      ],
      "id": "iQpSMdlg1Ams"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0PZzBtfv6qc"
      },
      "outputs": [],
      "source": [],
      "id": "n0PZzBtfv6qc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LykHAvh-uy4J"
      },
      "source": [
        "### Let's test with a video!"
      ],
      "id": "LykHAvh-uy4J"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKIjgWgjuyT2",
        "outputId": "b423a189-7815-4462-bb37-afec03601c81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-05-13 15:15:19--  https://www.dropbox.com/s/q3evjn917cwv9ax/scene_40.h5?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.80.18, 2620:100:6031:18::a27d:5112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.80.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/q3evjn917cwv9ax/scene_40.h5 [following]\n",
            "--2023-05-13 15:15:20--  https://www.dropbox.com/s/raw/q3evjn917cwv9ax/scene_40.h5\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc145348ac01982bad3f9db461f2.dl.dropboxusercontent.com/cd/0/inline/B7_1_v5JyUOfpUhDM01CBICsyK6-4KLxrfRBLEMd6vXG7FeS_lbEykTOtAfOIe-jvs8BxhAnMhVDEp8MAwvHkjUrZGtDK9S1By9FlWrazxnlthyedYVhU7n-DBb7LHOVrzgHuZGOspt96Wqlaw4_cOgJ9vZHK_7Sy8-TOTM8g5-QHQ/file# [following]\n",
            "--2023-05-13 15:15:20--  https://uc145348ac01982bad3f9db461f2.dl.dropboxusercontent.com/cd/0/inline/B7_1_v5JyUOfpUhDM01CBICsyK6-4KLxrfRBLEMd6vXG7FeS_lbEykTOtAfOIe-jvs8BxhAnMhVDEp8MAwvHkjUrZGtDK9S1By9FlWrazxnlthyedYVhU7n-DBb7LHOVrzgHuZGOspt96Wqlaw4_cOgJ9vZHK_7Sy8-TOTM8g5-QHQ/file\n",
            "Resolving uc145348ac01982bad3f9db461f2.dl.dropboxusercontent.com (uc145348ac01982bad3f9db461f2.dl.dropboxusercontent.com)... 162.125.81.15, 2620:100:6031:15::a27d:510f\n",
            "Connecting to uc145348ac01982bad3f9db461f2.dl.dropboxusercontent.com (uc145348ac01982bad3f9db461f2.dl.dropboxusercontent.com)|162.125.81.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/B783CmIPfrUUL2cq_ol32j155SELpwBtwu3T7qy9YvKp0xq0lbeUCgpj7cRsW-fAq51zVgSRLaPUrQUeDziK4kkattI1CUDeytin14TZHkuyMY-VcnMvXsM-iFPIFLzMMBXo5iquo7pYqC0yMaD_MB6RRYsee846WSe8IJSnZjAaAOm3KwpH82F6LtHmCJm2R59XUUaJbD2Pc9VldJldBOSH70BKfroO_s1-OFccZ6v7V-BjyHH1VQ96UZPGf4PZkWzimQi9ridHy-1_bEllgT-8uqmhv0V9FNVQnyS10qaQTlqT1CcLmqYc9rMDhHCIvP_fmpLXdA2wIaM6vOWOF64r4ln3pygODE0ocxBgoevo-FXxXP_StKv7NCu9vluf7zIabTdCjMKmEa-P4S0DT6vUqrNskuZzIqYnPOWWS_tfXA/file [following]\n",
            "--2023-05-13 15:15:21--  https://uc145348ac01982bad3f9db461f2.dl.dropboxusercontent.com/cd/0/inline2/B783CmIPfrUUL2cq_ol32j155SELpwBtwu3T7qy9YvKp0xq0lbeUCgpj7cRsW-fAq51zVgSRLaPUrQUeDziK4kkattI1CUDeytin14TZHkuyMY-VcnMvXsM-iFPIFLzMMBXo5iquo7pYqC0yMaD_MB6RRYsee846WSe8IJSnZjAaAOm3KwpH82F6LtHmCJm2R59XUUaJbD2Pc9VldJldBOSH70BKfroO_s1-OFccZ6v7V-BjyHH1VQ96UZPGf4PZkWzimQi9ridHy-1_bEllgT-8uqmhv0V9FNVQnyS10qaQTlqT1CcLmqYc9rMDhHCIvP_fmpLXdA2wIaM6vOWOF64r4ln3pygODE0ocxBgoevo-FXxXP_StKv7NCu9vluf7zIabTdCjMKmEa-P4S0DT6vUqrNskuZzIqYnPOWWS_tfXA/file\n",
            "Reusing existing connection to uc145348ac01982bad3f9db461f2.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 580613056 (554M) [application/octet-stream]\n",
            "Saving to: ‘vsrnet_test_lr’\n",
            "\n",
            "vsrnet_test_lr      100%[===================>] 553.71M  16.4MB/s    in 37s     \n",
            "\n",
            "2023-05-13 15:15:58 (15.0 MB/s) - ‘vsrnet_test_lr’ saved [580613056/580613056]\n",
            "\n",
            "--2023-05-13 15:15:58--  https://www.dropbox.com/s/lxm30agjddg72xe/scene_40.h5?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.69.18, 2620:100:6031:18::a27d:5112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.69.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/lxm30agjddg72xe/scene_40.h5 [following]\n",
            "--2023-05-13 15:16:00--  https://www.dropbox.com/s/raw/lxm30agjddg72xe/scene_40.h5\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uce7ffe59d39898d1d7732928812.dl.dropboxusercontent.com/cd/0/inline/B78CTMi4OYJxc0hR-eZVRP9eGOd4xuW-GGg1lmYLFphae859ZsYOgKhdau3yXraRFauVOqs5lr5iiNr1wltwX5vaBMIIh8xUnfWbuFi0-IJanN8tYcgXnZLvXgraLBCn_wtmrx9AZTxrQwBAs9TJ2Lmp-0MWG42e0gb2zb61C5UghQ/file# [following]\n",
            "--2023-05-13 15:16:00--  https://uce7ffe59d39898d1d7732928812.dl.dropboxusercontent.com/cd/0/inline/B78CTMi4OYJxc0hR-eZVRP9eGOd4xuW-GGg1lmYLFphae859ZsYOgKhdau3yXraRFauVOqs5lr5iiNr1wltwX5vaBMIIh8xUnfWbuFi0-IJanN8tYcgXnZLvXgraLBCn_wtmrx9AZTxrQwBAs9TJ2Lmp-0MWG42e0gb2zb61C5UghQ/file\n",
            "Resolving uce7ffe59d39898d1d7732928812.dl.dropboxusercontent.com (uce7ffe59d39898d1d7732928812.dl.dropboxusercontent.com)... 162.125.81.15, 2620:100:6031:15::a27d:510f\n",
            "Connecting to uce7ffe59d39898d1d7732928812.dl.dropboxusercontent.com (uce7ffe59d39898d1d7732928812.dl.dropboxusercontent.com)|162.125.81.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/B7-o1v5a9UjZTD6bNXNPdVpPwoo1nmlJj1mf3b9_-ARHG5t1tj2DyWgAZINTUE97-o0rtDdhg8IpdakmA-A0qhIocN7AzRHxcO1pxPxul1XSdFCqKmwMsb97JSXYBlnKovfq0lhgJ7fxoM8k4v0q_6Ja16C86d1EPcllbU3HIz1-eGO0lEhcET97EIDnW_BV8jjLMseg8twhW2guIKyDWs6ZJBQdv4HbjoB6FO_aYYTF6G1W1B8wmgWKO-56B00bh4b_1AMZSMJ9TF_84P2mofb3WfT9hS2CZD4RIER-WvQan2DBF1Jgmtuieyud-QR6ZS8P0DHNVrw6Q4pv2R7B1Vq5aGHZIrQNhlNMSrSOtMpAbxhySaj-UptwgrfnWv_fa0UNrknWS3aDZ5_-0qPQ3aI1Jf_YV6j8n2IYlAV2k0Gq6g/file [following]\n",
            "--2023-05-13 15:16:01--  https://uce7ffe59d39898d1d7732928812.dl.dropboxusercontent.com/cd/0/inline2/B7-o1v5a9UjZTD6bNXNPdVpPwoo1nmlJj1mf3b9_-ARHG5t1tj2DyWgAZINTUE97-o0rtDdhg8IpdakmA-A0qhIocN7AzRHxcO1pxPxul1XSdFCqKmwMsb97JSXYBlnKovfq0lhgJ7fxoM8k4v0q_6Ja16C86d1EPcllbU3HIz1-eGO0lEhcET97EIDnW_BV8jjLMseg8twhW2guIKyDWs6ZJBQdv4HbjoB6FO_aYYTF6G1W1B8wmgWKO-56B00bh4b_1AMZSMJ9TF_84P2mofb3WfT9hS2CZD4RIER-WvQan2DBF1Jgmtuieyud-QR6ZS8P0DHNVrw6Q4pv2R7B1Vq5aGHZIrQNhlNMSrSOtMpAbxhySaj-UptwgrfnWv_fa0UNrknWS3aDZ5_-0qPQ3aI1Jf_YV6j8n2IYlAV2k0Gq6g/file\n",
            "Reusing existing connection to uce7ffe59d39898d1d7732928812.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29035456 (28M) [application/octet-stream]\n",
            "Saving to: ‘vsrnet_test_hr’\n",
            "\n",
            "vsrnet_test_hr      100%[===================>]  27.69M  15.7MB/s    in 1.8s    \n",
            "\n",
            "2023-05-13 15:16:03 (15.7 MB/s) - ‘vsrnet_test_hr’ saved [29035456/29035456]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "uf4_test_dir = datasets_dir + '/uf4_test'\n",
        "\n",
        "vsrnet_test_lr = uf4_test_dir + '/vsrnet_test_lr.h5'\n",
        "vsrnet_test_hr = uf4_test_dir + '/vsrnet_test_hr.h5'\n",
        "\n",
        "!wget https://www.dropbox.com/s/q3evjn917cwv9ax/scene_40.h5?dl=0 -O vsrnet_test_lr\n",
        "!wget https://www.dropbox.com/s/lxm30agjddg72xe/scene_40.h5?dl=0  -O vsrnet_test_hr\n",
        "\n",
        "#!wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AAADzBQ7iA492oQ26ag67ZsKa/uf_4/test/LR_Bic_MC/scene_30.h5 -O vsrnet_test_lr\n",
        "#!wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AADSka3PgSR5EuCt9ByugfY6a/uf_4/test/HR/scene_30.h5 -O vsrnet_test_hr\n"
      ],
      "id": "mKIjgWgjuyT2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3oQP1rrvc3z"
      },
      "outputs": [],
      "source": [
        "path_LR_Bic_MC = './vsrnet_test_hr'\n",
        "path_HR = './vsrnet_test_hr'\n",
        "videos_h5_name = ['scene_40.h5']\n",
        "videos_h5_name.sort()"
      ],
      "id": "O3oQP1rrvc3z"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Gcsux3vwZJq"
      },
      "outputs": [],
      "source": [
        "h5_len = len(videos_h5_name)\n",
        "model_PSNR   = np.zeros(h5_len)\n",
        "model_SSIM   = np.zeros(h5_len)\n",
        "bicubic_PSNR = np.zeros(h5_len)\n",
        "bicubic_SSIM = np.zeros(h5_len)\n",
        "model_time   = np.zeros(h5_len)"
      ],
      "id": "2Gcsux3vwZJq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8U3KtNhwawy"
      },
      "outputs": [],
      "source": [
        "out_path = './'\n",
        "if not os.path.exists(out_path):\n",
        "    os.makedirs(out_path)"
      ],
      "id": "J8U3KtNhwawy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iA009Ixi2RPw"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "import math\n",
        "\n",
        "def psnr(img1, img2):\n",
        "    mse = numpy.mean( (img1 - img2) ** 2 )\n",
        "    if mse == 0:\n",
        "        return 100\n",
        "    PIXEL_MAX = 255.0\n",
        "    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))"
      ],
      "id": "iA009Ixi2RPw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSlXCgjh2dRH"
      },
      "outputs": [],
      "source": [
        "from scipy.ndimage import gaussian_filter\n",
        "\n",
        "from numpy.lib.stride_tricks import as_strided as ast\n",
        "\n",
        "\"\"\"\n",
        "Hat tip: http://stackoverflow.com/a/5078155/1828289\n",
        "\"\"\"\n",
        "def block_view(A, block=(3, 3)):\n",
        "    \"\"\"Provide a 2D block view to 2D array. No error checking made.\n",
        "    Therefore meaningful (as implemented) only for blocks strictly\n",
        "    compatible with the shape of A.\"\"\"\n",
        "    # simple shape and strides computations may seem at first strange\n",
        "    # unless one is able to recognize the 'tuple additions' involved ;-)\n",
        "    shape = (A.shape[0]// block[0], A.shape[1]// block[1])+ block\n",
        "    strides = (block[0]* A.strides[0], block[1]* A.strides[1])+ A.strides\n",
        "    return ast(A, shape= shape, strides= strides)\n",
        "\n",
        "\n",
        "def ssim(img1, img2, C1=0.01**2, C2=0.03**2):\n",
        "\n",
        "    bimg1 = block_view(img1, (4,4))\n",
        "    bimg2 = block_view(img2, (4,4))\n",
        "    s1  = numpy.sum(bimg1, (-1, -2))\n",
        "    s2  = numpy.sum(bimg2, (-1, -2))\n",
        "    ss  = numpy.sum(bimg1*bimg1, (-1, -2)) + numpy.sum(bimg2*bimg2, (-1, -2))\n",
        "    s12 = numpy.sum(bimg1*bimg2, (-1, -2))\n",
        "\n",
        "    vari = ss - s1*s1 - s2*s2\n",
        "    covar = s12 - s1*s2\n",
        "\n",
        "    ssim_map =  (2*s1*s2 + C1) * (2*covar + C2) / ((s1*s1 + s2*s2 + C1) * (vari + C2))\n",
        "    return numpy.mean(ssim_map)\n",
        "\n",
        "# FIXME there seems to be a problem with this code\n",
        "def ssim_exact(img1, img2, sd=1.5, C1=0.01**2, C2=0.03**2):\n",
        "\n",
        "    mu1 = gaussian_filter(img1, sd)\n",
        "    mu2 = gaussian_filter(img2, sd)\n",
        "    mu1_sq = mu1 * mu1\n",
        "    mu2_sq = mu2 * mu2\n",
        "    mu1_mu2 = mu1 * mu2\n",
        "    sigma1_sq = gaussian_filter(img1 * img1, sd) - mu1_sq\n",
        "    sigma2_sq = gaussian_filter(img2 * img2, sd) - mu2_sq\n",
        "    sigma12 = gaussian_filter(img1 * img2, sd) - mu1_mu2\n",
        "\n",
        "    ssim_num = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2))\n",
        "\n",
        "    ssim_den = ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
        "\n",
        "    ssim_map = ssim_num / ssim_den\n",
        "    return numpy.mean(ssim_map)"
      ],
      "id": "wSlXCgjh2dRH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1L_fRCrVwhHv",
        "outputId": "09abe57f-8084-4930-f31e-e6f7f28f8655"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:12<00:00,  1.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===> Test on Video Idx: 0 Complete: Model PSNR: 31.1959 dB, Model SSIM: 0.9991 , Bicubic PSNR:  31.3232 dB, Bicubic SSIM: 0.9995 , Average time: 680.5826\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import cv2\n",
        "\n",
        "video_idx = 0\n",
        "#   Read h5 file\n",
        "LR_Bic_MC_h5_file = h5py.File('./vsrnet_test_lr', 'r')\n",
        "LR_Bic_MC_h5_data = LR_Bic_MC_h5_file['data']\n",
        "HR_h5_file = h5py.File('./vsrnet_test_hr', 'r')\n",
        "HR_h5_data = HR_h5_file['data']\n",
        "    \n",
        "# load to memory\n",
        "HR_h5_data = HR_h5_data[()]#.value\n",
        "LR_Bic_MC_h5_data = LR_Bic_MC_h5_data[()]#.value\n",
        "    \n",
        "# transpose to correct order\n",
        "HR_h5_data = np.transpose(HR_h5_data, (3, 2, 1, 0))\n",
        "LR_Bic_MC_h5_data = np.transpose(LR_Bic_MC_h5_data, (3, 2, 1, 0))\n",
        "    \n",
        "frame_number = LR_Bic_MC_h5_data.shape[0]\n",
        "\n",
        "IS_REAL_TIME = False\n",
        "\n",
        "video_name = 'scene_40'\n",
        "    \n",
        "if not IS_REAL_TIME:\n",
        "    fps = 30\n",
        "    size = (LR_Bic_MC_h5_data.shape[3], LR_Bic_MC_h5_data.shape[2])\n",
        "    output_name = out_path + video_name.split('.')[0] + '.avi'\n",
        "    videoWriter = cv2.VideoWriter(output_name, cv2.VideoWriter_fourcc('M','J','P','G'), fps, size)\n",
        "#            videoWriter = cv2.VideoWriter(output_name, cv2.VideoWriter_fourcc(*'XVID'), fps, size)\n",
        "        \n",
        "#   Prepare to save PSNR and SSIM of the current video\n",
        "#   Each value corresponding to one test frame\n",
        "model_PSNR_cur   = np.zeros(frame_number)\n",
        "model_SSIM_cur   = np.zeros(frame_number)\n",
        "bicubic_PSNR_cur = np.zeros(frame_number)\n",
        "bicubic_SSIM_cur = np.zeros(frame_number)\n",
        "model_time_cur   = np.zeros(frame_number)\n",
        "    \n",
        "for idx in tqdm(range(0, frame_number)):\n",
        "    img_HR = HR_h5_data[idx, 0, :, :] #2D\n",
        "    img_LR_Bic_MC = LR_Bic_MC_h5_data[idx, :, :, :] #3D 5x1080x1920\n",
        "    \n",
        "    # Reshape to 4D\n",
        "    img_LR_Bic_MC = img_LR_Bic_MC.reshape((1, img_LR_Bic_MC.shape[0], img_LR_Bic_MC.shape[1], img_LR_Bic_MC.shape[2]))\n",
        "    \n",
        "    img_LR_Bic_MC = img_LR_Bic_MC.astype(np.float32)\n",
        "\n",
        "    img_LR_Bic_MC =  torch.from_numpy(img_LR_Bic_MC)\n",
        "                        \n",
        "    if torch.cuda.is_available():\n",
        "        img_LR_Bic_MC = img_LR_Bic_MC.cuda()\n",
        "\n",
        "    start = time.time()\n",
        "    if img_LR_Bic_MC.sum() != 0:\n",
        "        img_HR_net = model(img_LR_Bic_MC)\n",
        "\n",
        "    else:\n",
        "        img_HR_net = img_LR_Bic_MC[:,2,:,:]\n",
        "        img_HR_net = img_HR_net.reshape((1, 1, img_HR.shape[0], img_HR.shape[1])) # reshape to 1x1x1080x1920\n",
        "        \n",
        "    end = time.time() # measure the computation time\n",
        "    \n",
        "    img_HR_net = img_HR_net.cpu()\n",
        "    img_HR_net = img_HR_net.data[0].numpy()\n",
        "    img_HR_net *= 255.0\n",
        "    img_HR_net = img_HR_net.clip(0, 255)\n",
        "    img_HR_net = img_HR_net.astype(np.uint8)\n",
        "    \n",
        "    img_LR_Bic_MC = img_LR_Bic_MC.cpu()\n",
        "    img_LR_Bic = img_LR_Bic_MC[:, 2, :, :] # center frame\n",
        "    img_LR_Bic = img_LR_Bic.data[0].numpy()\n",
        "    img_LR_Bic *= 255.0\n",
        "    img_LR_Bic = img_LR_Bic.clip(0, 255)\n",
        "    img_LR_Bic = img_LR_Bic.astype(np.uint8)\n",
        "    \n",
        "    img_HR = img_HR.reshape((1, img_HR.shape[0], img_HR.shape[1]))\n",
        "    img_LR_Bic = img_LR_Bic.reshape((1, img_LR_Bic.shape[0], img_LR_Bic.shape[1]))\n",
        "\n",
        "    \n",
        "    model_PSNR_cur[idx]   = psnr((img_HR).reshape(img_HR.shape[1], img_HR.shape[2]).astype(int), (img_HR_net).reshape(img_HR_net.shape[1], img_HR_net.shape[2]).astype(int))\n",
        "    model_SSIM_cur[idx]   = ssim((img_HR).reshape(img_HR.shape[1], img_HR.shape[2]).astype(int), (img_HR_net).reshape(img_HR_net.shape[1], img_HR_net.shape[2]).astype(int))\n",
        "    bicubic_PSNR_cur[idx] = psnr((img_HR).reshape(img_HR.shape[1], img_HR.shape[2]).astype(int), (img_LR_Bic).reshape(img_LR_Bic.shape[1], img_LR_Bic.shape[2]).astype(int))\n",
        "    bicubic_SSIM_cur[idx] = ssim((img_HR).reshape(img_HR.shape[1], img_HR.shape[2]).astype(int), (img_LR_Bic).reshape(img_LR_Bic.shape[1], img_LR_Bic.shape[2]).astype(int))\n",
        "    model_time_cur[idx]   = (end-start)\n",
        "\n",
        "    # Repeat to 3 channels to save and display\n",
        "    img_HR_net = np.repeat(img_HR_net, 3, axis=0)\n",
        "    img_HR_net = np.transpose(img_HR_net, (1, 2, 0))\n",
        "\n",
        "    if IS_REAL_TIME:\n",
        "        plt.imshow(img_HR_net, cmap = 'gray')\n",
        "        plt.show()\n",
        "\n",
        "#                cv2.imshow('LR Video ', img_LR_Bic)\n",
        "#                cv2.imshow('SR Video ', img_HR_net)\n",
        "#                cv2.waitKey(DELAY_TIME)\n",
        "    else:\n",
        "        # save video\n",
        "        videoWriter.write(img_HR_net)\n",
        "    \n",
        "# Done video writing\n",
        "videoWriter.release()\n",
        "\n",
        "# Save PSNR and SSIM\n",
        "# Exclude PSNR = 100 cases (caused by black frames)\n",
        "cal_flag = (model_PSNR_cur != 100)\n",
        "model_PSNR[video_idx]   = np.mean(model_PSNR_cur[cal_flag])\n",
        "model_SSIM[video_idx]   = np.mean(model_SSIM_cur[cal_flag])\n",
        "bicubic_PSNR[video_idx] = np.mean(bicubic_PSNR_cur[cal_flag])\n",
        "bicubic_SSIM[video_idx] = np.mean(bicubic_SSIM_cur[cal_flag])\n",
        "model_time[video_idx]   = np.mean(model_time_cur[cal_flag])\n",
        "\n",
        "print(\"===> Test on Video Idx: \" + str(video_idx) +\" Complete: Model PSNR: {:.4f} dB, Model SSIM: {:.4f} , Bicubic PSNR:  {:.4f} dB, Bicubic SSIM: {:.4f} , Average time: {:.4f}\"\n",
        "  .format(model_PSNR[video_idx], model_SSIM[video_idx], bicubic_PSNR[video_idx], bicubic_SSIM[video_idx], model_time[video_idx]*1000))\n",
        "video_idx += 1"
      ],
      "id": "1L_fRCrVwhHv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sP3KU2cPHkcQ"
      },
      "outputs": [],
      "source": [],
      "id": "sP3KU2cPHkcQ"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}