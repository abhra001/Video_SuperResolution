{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38e60c3f",
        "outputId": "8b02da40-07df-4eaf-84bd-e2c06f0a3977"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorboard_logger\n",
            "  Downloading tensorboard_logger-0.1.0-py2.py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from tensorboard_logger) (3.20.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tensorboard_logger) (1.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboard_logger) (1.22.4)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard_logger) (1.10.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard_logger) (8.4.0)\n",
            "Installing collected packages: tensorboard_logger\n",
            "Successfully installed tensorboard_logger-0.1.0\n"
          ]
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "import os\n",
        "import torch\n",
        "import argparse\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import time\n",
        "\n",
        "from math import log10\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "# from data_utils import DatasetFromH5_SFSR\n",
        "# from model import Net_SRCNN\n",
        "!pip install tensorboard_logger\n",
        "from tensorboard_logger import configure, log_value\n",
        "\n",
        "# from data_utils import DatasetFromH5_MFSR\n",
        "# from model import Net_VSRNet\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.init as init\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "id": "38e60c3f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b2fd3a7"
      },
      "source": [
        "## SRCNN"
      ],
      "id": "9b2fd3a7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3c3ee631"
      },
      "outputs": [],
      "source": [
        "class Net_SRCNN(nn.Module):\n",
        "    def __init__(self, upscale_factor):\n",
        "        super(Net_SRCNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1,  64, (9, 9), (1, 1), (4, 4))\n",
        "        self.conv2 = nn.Conv2d(64, 32, (5, 5), (1, 1), (2, 2))\n",
        "        self.conv3 = nn.Conv2d(32, 1,  (5, 5), (1, 1), (2, 2))\n",
        "        \n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = (self.conv3(x))\n",
        "        return x\n",
        "    \n",
        "    def _initialize_weights(self):\n",
        "        init.orthogonal_(self.conv1.weight, init.calculate_gain('relu'))\n",
        "        init.orthogonal_(self.conv2.weight, init.calculate_gain('relu'))\n",
        "        init.orthogonal_(self.conv3.weight)"
      ],
      "id": "3c3ee631"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3c765661"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data.dataset import Dataset\n",
        "import h5py\n",
        "\n",
        "class DatasetFromH5_MFSR(Dataset):\n",
        "    def __init__(self, image_dataset_dir, target_dataset_dir, upscale_factor, input_transform=None, target_transform=None):\n",
        "        super(DatasetFromH5_MFSR, self).__init__()\n",
        "        \n",
        "        image_h5_file = h5py.File(image_dataset_dir, 'r')\n",
        "        target_h5_file = h5py.File(target_dataset_dir, 'r')\n",
        "        image_dataset = image_h5_file['data']\n",
        "        target_dataset = target_h5_file['data']\n",
        "        \n",
        "        self.image_datasets = image_dataset\n",
        "        self.target_datasets = target_dataset\n",
        "        self.total_count = image_dataset.shape[0]\n",
        "        \n",
        "        self.input_transform = input_transform\n",
        "        self.target_transform = target_transform\n",
        "        \n",
        "    def __getitem__(self, index):        \n",
        "        image = self.image_datasets[index, :, :, :]\n",
        "        target = self.target_datasets[index, [2], :, :]\n",
        "        \n",
        "        image  = image.astype(np.float32)\n",
        "        target = target.astype(np.float32)\n",
        "        \n",
        "        #   Notice that image is the bicubic upscaled LR image patch, in float format, in range [0, 1]\n",
        "#        image = image / 255.0 \n",
        "        #   Notice that target is the HR image patch, in uint8 format, in range [0, 255]\n",
        "        target = target / 255.0\n",
        "        \n",
        "        image =  torch.from_numpy(image)\n",
        "        target = torch.from_numpy(target)\n",
        "\n",
        "        return image, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.total_count"
      ],
      "id": "3c765661"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFf6x0DDXRYo"
      },
      "outputs": [],
      "source": [
        "data_dir = \"./data\"\n",
        "\n",
        "downloads_dir = data_dir + '/downloads'\n",
        "datasets_dir = data_dir + '/datasets'\n",
        "models_dir = data_dir + '/models'\n",
        "pretrained_models = data_dir + '/pretrained_models'\n",
        "\n",
        "os.makedirs(downloads_dir, exist_ok=True)\n",
        "os.makedirs(datasets_dir, exist_ok=True)\n",
        "os.makedirs(models_dir, exist_ok=True)\n",
        "os.makedirs(pretrained_models, exist_ok=True)\n",
        "\n",
        "uf4_train_dir = datasets_dir + '/uf4_train'\n",
        "uf4_val_dir = datasets_dir + '/uf4_val'\n",
        "\n",
        "srrnet_train_lr = uf4_train_dir + '/srrnet_train_lr.h5'\n",
        "srrnet_train_hr = uf4_train_dir + '/srrnet_train_hr.h5'\n",
        "\n",
        "srrnet_val_lr = uf4_val_dir + '/srrnet_val_lr.h5'\n",
        "srrnet_val_hr = uf4_val_dir + '/srrnet_val_hr.h5'\n",
        "\n",
        "#!wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AACDZmHK7d2JQi0ADaoliM04a/uf_4/train/Data_CDVL_LR_Bic_MC_uf_4_ps_72_fn_5_tpn_225000.h5 -O srrnet_train_lr\n",
        "#!wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AACmrvoqkXXnZTXUFsWvNDCsa/uf_4/train/Data_CDVL_HR_uf_4_ps_72_fn_5_tpn_225000.h5 -O srrnet_train_hr\n",
        "\n",
        "#!wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AADJnJmRvFxmf7sxEk5G0Uuma/uf_4/val/Data_CDVL_LR_Bic_MC_uf_4_ps_72_fn_5_tpn_45000.h5 -O srrnet_val_lr\n",
        "#!wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AAChoVG4fLqdpsmSuq9wrEvFa/uf_4/val/Data_CDVL_HR_uf_4_ps_72_fn_5_tpn_45000.h5 -O srrnet_val_hr\n",
        "\n"
      ],
      "id": "zFf6x0DDXRYo"
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "tZfw7GgSSZSb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad067180-6fc2-4c88-8f13-706b0fcc3480"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "id": "tZfw7GgSSZSb"
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Computer_Vision/train_subset_12800.pkl', 'rb') as f:\n",
        "    subset_train = pickle.load(f)"
      ],
      "metadata": {
        "id": "yxNOa8_gO39f"
      },
      "execution_count": null,
      "outputs": [],
      "id": "yxNOa8_gO39f"
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Computer_Vision/val_subset_12800.pkl', 'rb') as f:\n",
        "    subset_val = pickle.load(f)"
      ],
      "metadata": {
        "id": "pscx__FvTJkp"
      },
      "execution_count": null,
      "outputs": [],
      "id": "pscx__FvTJkp"
    },
    {
      "cell_type": "code",
      "source": [
        "upscale_factor = 4\n",
        "threads = 1\n",
        "batchSize = 256\n",
        "\n",
        "\n",
        "train_loader = DataLoader(dataset=subset_train, num_workers=threads, batch_size=batchSize, shuffle=False)\n",
        "val_loader = DataLoader(dataset=subset_val, num_workers=threads, batch_size=batchSize, shuffle=False)"
      ],
      "metadata": {
        "id": "A_8YXp3WnXrF"
      },
      "id": "A_8YXp3WnXrF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get the pretrained SRCNN"
      ],
      "metadata": {
        "id": "z9WRd1A80rWD"
      },
      "id": "z9WRd1A80rWD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f9d3f00-54ba-4011-b65f-8004cfd7982b",
        "id": "1-d52WyD0p_D"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-15 03:31:07--  https://www.dropbox.com/s/pd5b2ketm0oamhj/srcnn_x4.pth\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.80.18, 2620:100:6035:18::a27d:5512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.80.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/pd5b2ketm0oamhj/srcnn_x4.pth [following]\n",
            "--2023-05-15 03:31:07--  https://www.dropbox.com/s/raw/pd5b2ketm0oamhj/srcnn_x4.pth\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucad59d105883b63678ba14be57d.dl.dropboxusercontent.com/cd/0/inline/B8Enil6SCm_NjlKUnqFmCoc8rpuad2_69XG7kZptOspaAOENQI_dXosot9MtEEqz0l20dukiN1czqi-OIywXQKijf8XeHAE5zlfsK0q5-l9SKXDrfw9l-HGe0c9ES6MXjh6PT6tqnsGwUQs-vFB59flLp7lAVQIumndzf4FtIWr2UA/file# [following]\n",
            "--2023-05-15 03:31:08--  https://ucad59d105883b63678ba14be57d.dl.dropboxusercontent.com/cd/0/inline/B8Enil6SCm_NjlKUnqFmCoc8rpuad2_69XG7kZptOspaAOENQI_dXosot9MtEEqz0l20dukiN1czqi-OIywXQKijf8XeHAE5zlfsK0q5-l9SKXDrfw9l-HGe0c9ES6MXjh6PT6tqnsGwUQs-vFB59flLp7lAVQIumndzf4FtIWr2UA/file\n",
            "Resolving ucad59d105883b63678ba14be57d.dl.dropboxusercontent.com (ucad59d105883b63678ba14be57d.dl.dropboxusercontent.com)... 162.125.80.15, 2620:100:601a:15::a27d:70f\n",
            "Connecting to ucad59d105883b63678ba14be57d.dl.dropboxusercontent.com (ucad59d105883b63678ba14be57d.dl.dropboxusercontent.com)|162.125.80.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/B8FH8yZ5Ll-QvVT2lO_tVRNr3tiJ3uZ5m9TQ4tl8cKXRSEr_iEt56i4lhPKZ5JG9Q8Sp9u2LwM-cFTyuS7phmvUM60kc5t-0u4ocjqPQcklcFoRPI6kB9gZJnJ7poPDd0k0QbKozr7N-GkUSFoV2R69lHLFWVv8o-0sAQArIGmh_Sz--QXsNGBJvwV6fuZxX3fNcxoY0edeuRarLNL8ps-_fB1hC9nxyOm4zrAwv-WKRhQn0ZE2saLcHQv563g0XxAfybtzx4YO4t9EWX-SKCbsjvwlfAR4f9HPCl2dV_DZfWHupUnqBcRV_phyiVP7v562eJrTtFzZGhptWrRLBrjLFY-ZlYxC_o-rQw35s3OzVFw6wjaxgdcRRn-kxNSxueRb0IAk5bZXivdhFbyIffA-MOKoAR9V8n2J3O4AUHvsqWg/file [following]\n",
            "--2023-05-15 03:31:09--  https://ucad59d105883b63678ba14be57d.dl.dropboxusercontent.com/cd/0/inline2/B8FH8yZ5Ll-QvVT2lO_tVRNr3tiJ3uZ5m9TQ4tl8cKXRSEr_iEt56i4lhPKZ5JG9Q8Sp9u2LwM-cFTyuS7phmvUM60kc5t-0u4ocjqPQcklcFoRPI6kB9gZJnJ7poPDd0k0QbKozr7N-GkUSFoV2R69lHLFWVv8o-0sAQArIGmh_Sz--QXsNGBJvwV6fuZxX3fNcxoY0edeuRarLNL8ps-_fB1hC9nxyOm4zrAwv-WKRhQn0ZE2saLcHQv563g0XxAfybtzx4YO4t9EWX-SKCbsjvwlfAR4f9HPCl2dV_DZfWHupUnqBcRV_phyiVP7v562eJrTtFzZGhptWrRLBrjLFY-ZlYxC_o-rQw35s3OzVFw6wjaxgdcRRn-kxNSxueRb0IAk5bZXivdhFbyIffA-MOKoAR9V8n2J3O4AUHvsqWg/file\n",
            "Reusing existing connection to ucad59d105883b63678ba14be57d.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 230278 (225K) [application/octet-stream]\n",
            "Saving to: ‘./data/pretrained_models/srcnn_model.pth’\n",
            "\n",
            "./data/pretrained_m 100%[===================>] 224.88K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-05-15 03:31:09 (1.52 MB/s) - ‘./data/pretrained_models/srcnn_model.pth’ saved [230278/230278]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.dropbox.com/s/pd5b2ketm0oamhj/srcnn_x4.pth -O {pretrained_models}/srcnn_model.pth"
      ],
      "id": "1-d52WyD0p_D"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWBS2iqJ0p_E"
      },
      "outputs": [],
      "source": [
        "upscale_factor = 4\n",
        "srcnn = Net_SRCNN(upscale_factor=upscale_factor)\n",
        "\n",
        "state_dict = srcnn.state_dict()\n",
        "for n, p in torch.load(pretrained_models+'/srcnn_model.pth', map_location=lambda storage, loc: storage).items():\n",
        "    if n in state_dict.keys():\n",
        "        state_dict[n].copy_(p)\n",
        "    else:\n",
        "        raise KeyError(n)\n",
        "\n",
        "torch.save(srcnn, pretrained_models+'/srcnn_model.pth')"
      ],
      "id": "HWBS2iqJ0p_E"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the VSRNet"
      ],
      "metadata": {
        "id": "nyMNCGnL00tK"
      },
      "id": "nyMNCGnL00tK"
    },
    {
      "cell_type": "code",
      "source": [
        "class Net_VSRNet(nn.Module):\n",
        "    def __init__(self, upscale_factor, srcnn_model):\n",
        "        super(Net_VSRNet, self).__init__()\n",
        "\n",
        "        self.conv1_f0 = nn.Conv2d(1,  64, (9, 9), (1, 1), (4, 4))\n",
        "        self.conv1_f1 = nn.Conv2d(1,  64, (9, 9), (1, 1), (4, 4))\n",
        "        self.conv1_f2 = nn.Conv2d(1,  64, (9, 9), (1, 1), (4, 4))\n",
        "        \n",
        "        \n",
        "        self.conv2_1 = nn.Conv2d(192, 32, (5, 5), (1, 1), (2, 2))\n",
        "        self.conv2_2 = nn.Conv2d(192, 32, (5, 5), (1, 1), (2, 2))\n",
        "        self.conv3 = nn.Conv2d(64, 1,  (5, 5), (1, 1), (2, 2))\n",
        "        \n",
        "        self.srcnn_model = srcnn_model\n",
        "        self.upscale_factor = upscale_factor\n",
        "        \n",
        "        self._initialize_weights()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        h10 = x[:,[0],:,:]\n",
        "        h11 = x[:,[1],:,:]\n",
        "        h12 = x[:,[2],:,:]\n",
        "        h13 = x[:,[3],:,:]\n",
        "        h14 = x[:,[4],:,:] \n",
        "\n",
        "        h10 = self.conv1_f0(h10)\n",
        "        h11 = self.conv1_f1(h11)\n",
        "        h12 = self.conv1_f2(h12)\n",
        "        h13 = self.conv1_f1(h13)\n",
        "        h14 = self.conv1_f0(h14) \n",
        "\n",
        "        x1 = F.relu(torch.cat((h10, h11, h12), 1))\n",
        "        x2 = F.relu(torch.cat((h12, h13, h14), 1))\n",
        "\n",
        "        x1 = self.conv2_1(x1)\n",
        "        x2 = self.conv2_2(x2)\n",
        "\n",
        "        x = F.relu(torch.cat((x1,x2),1))\n",
        "        x = (self.conv3(x))\n",
        "\n",
        "        return x\n",
        "    \n",
        "    def _initialize_weights(self):\n",
        "        \n",
        "        srcnn_model = torch.load(self.srcnn_model, map_location=lambda storage, loc: storage) # forcing to load to CPU       \n",
        "        \n",
        "        self.conv1_f0.weight.data = (srcnn_model.conv1.weight.data).clone()\n",
        "        self.conv1_f1.weight.data = (srcnn_model.conv1.weight.data).clone()\n",
        "        self.conv1_f2.weight.data = (srcnn_model.conv1.weight.data).clone()\n",
        "        \n",
        "        self.conv1_f0.bias.data = (srcnn_model.conv1.bias.data).clone()\n",
        "        self.conv1_f1.bias.data = (srcnn_model.conv1.bias.data).clone()\n",
        "        self.conv1_f2.bias.data = (srcnn_model.conv1.bias.data).clone()\n",
        "        \n",
        "        self.conv2_1.weight.data = torch.cat((srcnn_model.conv2.weight.data, \n",
        "                                            srcnn_model.conv2.weight.data, \n",
        "                                            srcnn_model.conv2.weight.data), 1).clone()/3.0\n",
        "\n",
        "        self.conv2_2.weight.data = torch.cat((srcnn_model.conv2.weight.data, \n",
        "                                            srcnn_model.conv2.weight.data, \n",
        "                                            srcnn_model.conv2.weight.data), 1).clone()/3.0\n",
        "        \n",
        "        self.conv2_1.bias.data = (srcnn_model.conv2.bias.data).clone()     \n",
        "        self.conv2_2.bias.data = (srcnn_model.conv2.bias.data).clone()\n",
        "\n",
        "        self.conv3.weight.data = torch.cat((srcnn_model.conv3.weight.data, \n",
        "                                            srcnn_model.conv3.weight.data), 1).clone()/2.0\n",
        "        \n",
        "        self.conv3.bias.data = (srcnn_model.conv3.bias.data).clone()"
      ],
      "metadata": {
        "id": "huh27ENvA3te"
      },
      "id": "huh27ENvA3te",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNxNuIVC0p_F"
      },
      "outputs": [],
      "source": [
        "model = Net_VSRNet(upscale_factor=upscale_factor, srcnn_model=pretrained_models+'/srcnn_model.pth')\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "    criterion = criterion.cuda()"
      ],
      "id": "mNxNuIVC0p_F"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5E2UvHTL1Amq"
      },
      "outputs": [],
      "source": [
        "lr = 0.001\n",
        "optimizer = optim.Adam([{'params': model.conv1_f0.parameters()},\n",
        "                        {'params': model.conv1_f1.parameters()},\n",
        "                        {'params': model.conv1_f2.parameters()},\n",
        "                        {'params': model.conv2_1.parameters()},\n",
        "                        {'params': model.conv2_2.parameters()},\n",
        "                        {'params': model.conv3.parameters(), 'lr': lr/10.0}\n",
        "                        ], lr=lr)"
      ],
      "id": "5E2UvHTL1Amq"
    },
    {
      "cell_type": "code",
      "source": [
        "configure(\"tensorBoardRuns/VSRNet-relu-mid-fusion-pretrain-sym-x4-batch-128-CDVL-225000x5x72x72-wd\")"
      ],
      "metadata": {
        "id": "mtt9OcFH1NLx"
      },
      "id": "mtt9OcFH1NLx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48z_dtoq1Amr"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train(epoch):\n",
        "    lr = 0.001\n",
        "    epoch_loss = 0\n",
        "    epoch_psnr = 0\n",
        "    start = time.time()\n",
        "    #   Step up learning rate decay\n",
        "    #   The network have 3 layers\n",
        "    lr = lr * (0.1 ** (epoch // (nEpochs // 4)))\n",
        "    \n",
        "    optimizer.param_groups[0]['lr'] = lr\n",
        "    optimizer.param_groups[1]['lr'] = lr\n",
        "    optimizer.param_groups[2]['lr'] = lr\n",
        "    optimizer.param_groups[3]['lr'] = lr\n",
        "    optimizer.param_groups[4]['lr'] = lr/10.0\n",
        "    \n",
        "\n",
        "    n = 0\n",
        "    for iteration, batch in enumerate(train_loader, 1):\n",
        "        if n >= 49:\n",
        "          break \n",
        "        n = n+1\n",
        "        image, target = Variable(batch[0]), Variable(batch[1])\n",
        "        if torch.cuda.is_available():\n",
        "            image = image.cuda()\n",
        "            target = target.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(model(image), target)\n",
        "        psnr = 10 * log10(1 / loss.data.item())\n",
        "        epoch_loss += loss.data.item()\n",
        "        epoch_psnr += psnr\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "    end = time.time()\n",
        "    print(\"===> Epoch {} Complete: lr: {}, Avg. Loss: {:.4f}, Avg.PSNR:  {:.4f} dB, Time: {:.4f}\".format(epoch, lr, epoch_loss / len(train_loader), epoch_psnr / len(train_loader), (end-start)))\n",
        "    \n",
        "    log_value('train_loss', epoch_loss / len(train_loader), epoch)\n",
        "    log_value('train_psnr', epoch_psnr / len(train_loader), epoch)"
      ],
      "id": "48z_dtoq1Amr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1GBHIoj1Amr"
      },
      "outputs": [],
      "source": [
        "def val(epoch):\n",
        "    #   Validation on CDVL val set\n",
        "    lr = 0.001\n",
        "    avg_psnr = 0\n",
        "    avg_mse = 0\n",
        "    frame_count = 0\n",
        "    start = time.time()\n",
        "    n = 0\n",
        "    for batch in val_loader:\n",
        "        if n >= 49:\n",
        "          break \n",
        "        n = n+1\n",
        "        image, target = Variable(batch[0]), Variable(batch[1])\n",
        "        if torch.cuda.is_available():\n",
        "            image = image.cuda()\n",
        "            target = target.cuda()\n",
        "\n",
        "        prediction = model(image)\n",
        "\n",
        "        for i in range(0, image.shape[0]):\n",
        "            mse = criterion(prediction[i], target[i])\n",
        "            psnr = 10 * log10(1 / mse.data.item())\n",
        "            avg_psnr += psnr\n",
        "            avg_mse  += mse.data.item()\n",
        "            frame_count += 1\n",
        "\n",
        "    end = time.time()\n",
        "    print(\"===> Epoch {} Validation CDVL: Avg. Loss: {:.4f}, Avg.PSNR:  {:.4f} dB, Time: {:.4f}\".format(epoch, avg_mse / frame_count, avg_psnr / frame_count, (end-start)))\n",
        "\n",
        "    log_value('val_loss', avg_mse / frame_count, epoch)\n",
        "    log_value('val_psnr', avg_psnr / frame_count, epoch)"
      ],
      "id": "b1GBHIoj1Amr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEDjfLqW1Amr"
      },
      "outputs": [],
      "source": [
        "def checkpoint(epoch):\n",
        "    if epoch%10 == 0:\n",
        "        if not os.path.exists(\"epochs_VSRNet\"):\n",
        "            os.makedirs(\"epochs_VSRNet\")\n",
        "        model_out_path = \"epochs_VSRNet/\" + \"model_epoch_{}.pth\".format(epoch)\n",
        "        torch.save(model, model_out_path)\n",
        "        print(\"Checkpoint saved to {}\".format(model_out_path))"
      ],
      "id": "bEDjfLqW1Amr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f0e3ffe-7322-413b-b3ea-adc83b532b0b",
        "id": "iQpSMdlg1Ams"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===> Epoch 0 Validation CDVL: Avg. Loss: 0.0006, Avg.PSNR:  39.2561 dB, Time: 18.3227\n",
            "Checkpoint saved to epochs_VSRNet/model_epoch_0.pth\n",
            "===> Epoch 1 Complete: lr: 0.001, Avg. Loss: 0.0001, Avg.PSNR:  1.7091 dB, Time: 27.9084\n",
            "===> Epoch 1 Validation CDVL: Avg. Loss: 0.0008, Avg.PSNR:  35.1149 dB, Time: 10.8099\n",
            "===> Epoch 2 Complete: lr: 0.001, Avg. Loss: 0.0000, Avg.PSNR:  1.9629 dB, Time: 27.2015\n",
            "===> Epoch 2 Validation CDVL: Avg. Loss: 0.0007, Avg.PSNR:  37.4449 dB, Time: 10.9607\n",
            "===> Epoch 3 Complete: lr: 0.001, Avg. Loss: 0.0000, Avg.PSNR:  2.0992 dB, Time: 33.9735\n",
            "===> Epoch 3 Validation CDVL: Avg. Loss: 0.0006, Avg.PSNR:  37.9565 dB, Time: 11.2189\n",
            "===> Epoch 4 Complete: lr: 0.001, Avg. Loss: 0.0000, Avg.PSNR:  2.1115 dB, Time: 33.7311\n",
            "===> Epoch 4 Validation CDVL: Avg. Loss: 0.0006, Avg.PSNR:  37.6733 dB, Time: 11.2162\n",
            "===> Epoch 5 Complete: lr: 0.0001, Avg. Loss: 0.0000, Avg.PSNR:  2.1287 dB, Time: 33.8992\n",
            "===> Epoch 5 Validation CDVL: Avg. Loss: 0.0006, Avg.PSNR:  38.7443 dB, Time: 11.1978\n",
            "===> Epoch 6 Complete: lr: 0.0001, Avg. Loss: 0.0000, Avg.PSNR:  2.1362 dB, Time: 33.8128\n",
            "===> Epoch 6 Validation CDVL: Avg. Loss: 0.0006, Avg.PSNR:  39.0671 dB, Time: 11.2308\n",
            "===> Epoch 7 Complete: lr: 0.0001, Avg. Loss: 0.0000, Avg.PSNR:  2.1382 dB, Time: 33.8770\n",
            "===> Epoch 7 Validation CDVL: Avg. Loss: 0.0006, Avg.PSNR:  38.9851 dB, Time: 11.2378\n",
            "===> Epoch 8 Complete: lr: 0.0001, Avg. Loss: 0.0000, Avg.PSNR:  2.1361 dB, Time: 33.8339\n",
            "===> Epoch 8 Validation CDVL: Avg. Loss: 0.0006, Avg.PSNR:  38.8295 dB, Time: 11.2503\n",
            "===> Epoch 9 Complete: lr: 0.0001, Avg. Loss: 0.0000, Avg.PSNR:  2.1320 dB, Time: 33.8901\n",
            "===> Epoch 9 Validation CDVL: Avg. Loss: 0.0006, Avg.PSNR:  38.7195 dB, Time: 11.2817\n",
            "===> Epoch 10 Complete: lr: 1.0000000000000003e-05, Avg. Loss: 0.0000, Avg.PSNR:  2.1361 dB, Time: 33.8912\n",
            "===> Epoch 10 Validation CDVL: Avg. Loss: 0.0006, Avg.PSNR:  38.9814 dB, Time: 11.2500\n",
            "Checkpoint saved to epochs_VSRNet/model_epoch_10.pth\n",
            "===> Epoch 11 Complete: lr: 1.0000000000000003e-05, Avg. Loss: 0.0000, Avg.PSNR:  2.1381 dB, Time: 33.8595\n",
            "===> Epoch 11 Validation CDVL: Avg. Loss: 0.0006, Avg.PSNR:  38.8902 dB, Time: 11.2168\n",
            "===> Epoch 12 Complete: lr: 1.0000000000000003e-05, Avg. Loss: 0.0000, Avg.PSNR:  2.1350 dB, Time: 33.8615\n",
            "===> Epoch 12 Validation CDVL: Avg. Loss: 0.0006, Avg.PSNR:  38.7630 dB, Time: 11.2801\n",
            "===> Epoch 13 Complete: lr: 1.0000000000000003e-05, Avg. Loss: 0.0000, Avg.PSNR:  2.1317 dB, Time: 33.8758\n",
            "===> Epoch 13 Validation CDVL: Avg. Loss: 0.0006, Avg.PSNR:  38.7638 dB, Time: 11.1951\n",
            "===> Epoch 14 Complete: lr: 1.0000000000000003e-05, Avg. Loss: 0.0000, Avg.PSNR:  2.1315 dB, Time: 33.8346\n",
            "===> Epoch 14 Validation CDVL: Avg. Loss: 0.0006, Avg.PSNR:  38.9543 dB, Time: 11.1833\n",
            "===> Epoch 15 Complete: lr: 1.0000000000000002e-06, Avg. Loss: 0.0000, Avg.PSNR:  2.1350 dB, Time: 33.8624\n",
            "===> Epoch 15 Validation CDVL: Avg. Loss: 0.0006, Avg.PSNR:  39.0970 dB, Time: 11.3294\n",
            "===> Epoch 16 Complete: lr: 1.0000000000000002e-06, Avg. Loss: 0.0000, Avg.PSNR:  2.1379 dB, Time: 33.8244\n",
            "===> Epoch 16 Validation CDVL: Avg. Loss: 0.0006, Avg.PSNR:  39.2535 dB, Time: 11.2298\n",
            "===> Epoch 17 Complete: lr: 1.0000000000000002e-06, Avg. Loss: 0.0000, Avg.PSNR:  2.1408 dB, Time: 33.8337\n",
            "===> Epoch 17 Validation CDVL: Avg. Loss: 0.0006, Avg.PSNR:  39.2808 dB, Time: 11.1963\n",
            "===> Epoch 18 Complete: lr: 1.0000000000000002e-06, Avg. Loss: 0.0000, Avg.PSNR:  2.1417 dB, Time: 33.8505\n",
            "===> Epoch 18 Validation CDVL: Avg. Loss: 0.0006, Avg.PSNR:  39.2458 dB, Time: 11.2610\n",
            "===> Epoch 19 Complete: lr: 1.0000000000000002e-06, Avg. Loss: 0.0000, Avg.PSNR:  2.1415 dB, Time: 33.8475\n",
            "===> Epoch 19 Validation CDVL: Avg. Loss: 0.0006, Avg.PSNR:  39.1696 dB, Time: 11.2296\n",
            "===> Epoch 20 Complete: lr: 1.0000000000000002e-07, Avg. Loss: 0.0000, Avg.PSNR:  2.1406 dB, Time: 33.8405\n",
            "===> Epoch 20 Validation CDVL: Avg. Loss: 0.0006, Avg.PSNR:  39.0569 dB, Time: 11.2500\n",
            "Checkpoint saved to epochs_VSRNet/model_epoch_20.pth\n"
          ]
        }
      ],
      "source": [
        "nEpochs = 20\n",
        "lr = 0.001\n",
        "\n",
        "val(0)\n",
        "checkpoint(0)\n",
        "for epoch in range(1, nEpochs + 1):\n",
        "    train(epoch)\n",
        "    val(epoch)\n",
        "    checkpoint(epoch)"
      ],
      "id": "iQpSMdlg1Ams"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n0PZzBtfv6qc"
      },
      "id": "n0PZzBtfv6qc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's test with a video!"
      ],
      "metadata": {
        "id": "LykHAvh-uy4J"
      },
      "id": "LykHAvh-uy4J"
    },
    {
      "cell_type": "code",
      "source": [
        "uf4_test_dir = datasets_dir + '/uf4_test'\n",
        "\n",
        "vsrnet_test_lr = uf4_test_dir + '/vsrnet_test_lr.h5'\n",
        "vsrnet_test_hr = uf4_test_dir + '/vsrnet_test_hr.h5'\n",
        "\n",
        "# !wget https://www.dropbox.com/s/q3evjn917cwv9ax/scene_40.h5?dl=0 -O vsrnet_test_lr\n",
        "# !wget https://www.dropbox.com/s/lxm30agjddg72xe/scene_40.h5?dl=0  -O vsrnet_test_hr\n",
        "\n",
        "# !wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AAADzBQ7iA492oQ26ag67ZsKa/uf_4/test/LR_Bic_MC/scene_30.h5 -O vsrnet_test_lr\n",
        "# !wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AADSka3PgSR5EuCt9ByugfY6a/uf_4/test/HR/scene_30.h5 -O vsrnet_test_hr\n",
        "\n",
        "# !wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AAAjVWqLkx3FeH0cFb8z-MWja/uf_4/test/LR_Bic_MC/scene_3.h5 -O vsrnet_test_lr\n",
        "# !wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AACUf_htc2UyZ09RZEf8eMhna/uf_4/test/HR/scene_3.h5 -O vsrnet_test_hr\n",
        "\n",
        "# !wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AACdGmQj7kCXz_v27fwWs2h1a/uf_4/test/LR_Bic_MC/scene_5.h5 -O vsrnet_test_lr\n",
        "# !wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AADsFOppMEsrQDpocSXC97DXa/uf_4/test/HR/scene_5.h5 -O vsrnet_test_hr\n",
        "\n",
        "# !wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AABDmXatC4VxX8O_EEuAt_x2a/uf_4/test/LR_Bic_MC/scene_6.h5 -O vsrnet_test_lr\n",
        "# !wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AAA08OjOclgpbRh_mB9sSCHUa/uf_4/test/HR/scene_6.h5 -O vsrnet_test_hr\n",
        "\n",
        "# !wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AABbQCBbku1JodA6ApYbWNDWa/uf_4/test/LR_Bic_MC/scene_8.h5 -O vsrnet_test_lr\n",
        "# !wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AAB3WPxCO-XHWj8M4iFWfpTca/uf_4/test/HR/scene_8.h5 -O vsrnet_test_hr\n",
        "\n",
        "# !wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AAA9Npqq8KogOTeDnnNExSKAa/uf_4/test/LR_Bic_MC/scene_13.h5 -O vsrnet_test_lr\n",
        "# !wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AABN3ZUwImVXTaEUzV-duw8ca/uf_4/test/HR/scene_13.h5 -O vsrnet_test_hr\n",
        "\n",
        "# !wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AAAnoBic_NLHdVLrWHLpwjm5a/uf_4/test/LR_Bic_MC/scene_15.h5 -O vsrnet_test_lr\n",
        "# !wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AAAojG-9M8KrZZBjIHKGvFsZa/uf_4/test/HR/scene_15.h5 -O vsrnet_test_hr\n",
        "\n",
        "# !wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AAAW4h46W61Y_EqLpBg_YrCza/uf_4/test/LR_Bic_MC/scene_21.h5 -O vsrnet_test_lr\n",
        "# !wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AABHWzPMBoFcdIBMeDhOqWjBa/uf_4/test/HR/scene_21.h5 -O vsrnet_test_hr\n",
        "\n",
        "# !wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AABmT-hCg6YPrtf0EzLxEZIIa/uf_4/test/LR_Bic_MC/scene_24.h5 -O vsrnet_test_lr\n",
        "# !wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AACVoNl0j9axZPVsnvUT55xMa/uf_4/test/HR/scene_24.h5 -O vsrnet_test_hr\n",
        "\n",
        "# !wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AAAf3gSWeQAebAunmpALVCu_a/uf_4/test/LR_Bic_MC/scene_25.h5 -O vsrnet_test_lr\n",
        "# !wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AADAUSF400EgaM3pZZS0hoXta/uf_4/test/HR/scene_25.h5 -O vsrnet_test_hr\n",
        "\n",
        "# !wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AAAWpRE5BzU5K7qYSzNtEkECa/uf_4/test/LR_Bic_MC/scene_27.h5 -O vsrnet_test_lr\n",
        "# !wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AAA1gx98FhUE6btMBQ7Tb08ca/uf_4/test/HR/scene_27.h5 -O vsrnet_test_hr\n",
        "\n",
        "# !wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AABowQui4h5OFqoP5GBOZvyaa/uf_4/test/LR_Bic_MC/scene_28.h5 -O vsrnet_test_lr\n",
        "# !wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AABedknvBLJDyo1DnOZiX4cTa/uf_4/test/HR/scene_28.h5 -O vsrnet_test_hr\n",
        "\n",
        "!wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AAADzBQ7iA492oQ26ag67ZsKa/uf_4/test/LR_Bic_MC/scene_30.h5 -O vsrnet_test_lr\n",
        "!wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AADSka3PgSR5EuCt9ByugfY6a/uf_4/test/HR/scene_30.h5 -O vsrnet_test_hr\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKIjgWgjuyT2",
        "outputId": "a7a7d2dd-997b-41c1-bec0-50d83bf24dd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-15 04:29:10--  https://www.dropbox.com/sh/1jz9zeer9wxetx2/AAADzBQ7iA492oQ26ag67ZsKa/uf_4/test/LR_Bic_MC/scene_30.h5\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:6035:18::a27d:5512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /sh/raw/1jz9zeer9wxetx2/AAADzBQ7iA492oQ26ag67ZsKa/uf_4/test/LR_Bic_MC/scene_30.h5 [following]\n",
            "--2023-05-15 04:29:11--  https://www.dropbox.com/sh/raw/1jz9zeer9wxetx2/AAADzBQ7iA492oQ26ag67ZsKa/uf_4/test/LR_Bic_MC/scene_30.h5\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc8d217b4e8934b5d1efa035c5fb.dl.dropboxusercontent.com/cd/0/inline/B8GTfmAfWXHot3RWYWPmygG0EIUBimVAz1VIqvnxeNbbsFqOhH-VA_JsbusIrBIUzMjhukcmH1_vnUu14tuLlHAmNoObZJgG_x8gvrgS0eu2yLTVrlmRWO4KYNL6u5bTVW_5uYcPNh754azUfWO1T49R0kfP8rYGx9Fk0KMZdW5-JQ/file# [following]\n",
            "--2023-05-15 04:29:12--  https://uc8d217b4e8934b5d1efa035c5fb.dl.dropboxusercontent.com/cd/0/inline/B8GTfmAfWXHot3RWYWPmygG0EIUBimVAz1VIqvnxeNbbsFqOhH-VA_JsbusIrBIUzMjhukcmH1_vnUu14tuLlHAmNoObZJgG_x8gvrgS0eu2yLTVrlmRWO4KYNL6u5bTVW_5uYcPNh754azUfWO1T49R0kfP8rYGx9Fk0KMZdW5-JQ/file\n",
            "Resolving uc8d217b4e8934b5d1efa035c5fb.dl.dropboxusercontent.com (uc8d217b4e8934b5d1efa035c5fb.dl.dropboxusercontent.com)... 162.125.80.15, 2620:100:6035:15::a27d:550f\n",
            "Connecting to uc8d217b4e8934b5d1efa035c5fb.dl.dropboxusercontent.com (uc8d217b4e8934b5d1efa035c5fb.dl.dropboxusercontent.com)|162.125.80.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/B8HyqhHFPudAFQnYF4ztG21BBQqbrc8ZHc3y1MwUvFGk15b9FNtjgglxkwGNqHv5_yiXj_E7P71OnFA-Pm5TyN1FIIQyIt9BoJlAY1iV5bLtcaAW6UGiZFQRlD0FJB4q6WXxzxavXkCztL2TMcvxaU7l07t0M9asRxH4RtPtv1JUa2Xynyz9TIgDzk7ucd2rFdS656jp0-5tEN-pTFf8e-fQoQ2qgX9bmjsp8Fvw9N2VQFMeru5vag7ZvpN83ncTId6whMS6AYT0YVrpc0R2HEwaslIY_kG6XNgICblqGCzMZis3hx70YPEf5APzGVxYqhbSOSwLTzlHg23wwMQ5hnpF7HeGoSg0Jdnk8CQogueyS6-UIFR9WpEzlJqbXwc8Y2JmpUgFo50kHRfYnn42dsl6wv4Vai-Tl6ULyQCAuFPuCA/file [following]\n",
            "--2023-05-15 04:29:13--  https://uc8d217b4e8934b5d1efa035c5fb.dl.dropboxusercontent.com/cd/0/inline2/B8HyqhHFPudAFQnYF4ztG21BBQqbrc8ZHc3y1MwUvFGk15b9FNtjgglxkwGNqHv5_yiXj_E7P71OnFA-Pm5TyN1FIIQyIt9BoJlAY1iV5bLtcaAW6UGiZFQRlD0FJB4q6WXxzxavXkCztL2TMcvxaU7l07t0M9asRxH4RtPtv1JUa2Xynyz9TIgDzk7ucd2rFdS656jp0-5tEN-pTFf8e-fQoQ2qgX9bmjsp8Fvw9N2VQFMeru5vag7ZvpN83ncTId6whMS6AYT0YVrpc0R2HEwaslIY_kG6XNgICblqGCzMZis3hx70YPEf5APzGVxYqhbSOSwLTzlHg23wwMQ5hnpF7HeGoSg0Jdnk8CQogueyS6-UIFR9WpEzlJqbXwc8Y2JmpUgFo50kHRfYnn42dsl6wv4Vai-Tl6ULyQCAuFPuCA/file\n",
            "Reusing existing connection to uc8d217b4e8934b5d1efa035c5fb.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 580613056 (554M) [application/octet-stream]\n",
            "Saving to: ‘vsrnet_test_lr’\n",
            "\n",
            "vsrnet_test_lr      100%[===================>] 553.71M  30.5MB/s    in 20s     \n",
            "\n",
            "2023-05-15 04:29:33 (28.0 MB/s) - ‘vsrnet_test_lr’ saved [580613056/580613056]\n",
            "\n",
            "--2023-05-15 04:29:33--  https://www.dropbox.com/sh/1jz9zeer9wxetx2/AADSka3PgSR5EuCt9ByugfY6a/uf_4/test/HR/scene_30.h5\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:6035:18::a27d:5512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /sh/raw/1jz9zeer9wxetx2/AADSka3PgSR5EuCt9ByugfY6a/uf_4/test/HR/scene_30.h5 [following]\n",
            "--2023-05-15 04:29:34--  https://www.dropbox.com/sh/raw/1jz9zeer9wxetx2/AADSka3PgSR5EuCt9ByugfY6a/uf_4/test/HR/scene_30.h5\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc23e121cc8c5f0a04291876f7be.dl.dropboxusercontent.com/cd/0/inline/B8HQarjOy2VS_hrbdxTFOpxZDvJel7xHii2v36SrmY-TXkOL8I634kIpcBk0QV8C-Bkn9phuOk4btslIxULUsEg-rj9iQz8IBE7J_OT95PX0YKok5fa5PAEe7RaWRzHu6jpbAAx0P5zHdAp9hkxprZsoz4fiFJMhFwRIJZvVhAH5sQ/file# [following]\n",
            "--2023-05-15 04:29:35--  https://uc23e121cc8c5f0a04291876f7be.dl.dropboxusercontent.com/cd/0/inline/B8HQarjOy2VS_hrbdxTFOpxZDvJel7xHii2v36SrmY-TXkOL8I634kIpcBk0QV8C-Bkn9phuOk4btslIxULUsEg-rj9iQz8IBE7J_OT95PX0YKok5fa5PAEe7RaWRzHu6jpbAAx0P5zHdAp9hkxprZsoz4fiFJMhFwRIJZvVhAH5sQ/file\n",
            "Resolving uc23e121cc8c5f0a04291876f7be.dl.dropboxusercontent.com (uc23e121cc8c5f0a04291876f7be.dl.dropboxusercontent.com)... 162.125.80.15, 2620:100:6035:15::a27d:550f\n",
            "Connecting to uc23e121cc8c5f0a04291876f7be.dl.dropboxusercontent.com (uc23e121cc8c5f0a04291876f7be.dl.dropboxusercontent.com)|162.125.80.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29035456 (28M) [text/plain]\n",
            "Saving to: ‘vsrnet_test_hr’\n",
            "\n",
            "vsrnet_test_hr      100%[===================>]  27.69M  12.1MB/s    in 2.3s    \n",
            "\n",
            "2023-05-15 04:29:38 (12.1 MB/s) - ‘vsrnet_test_hr’ saved [29035456/29035456]\n",
            "\n"
          ]
        }
      ],
      "id": "mKIjgWgjuyT2"
    },
    {
      "cell_type": "code",
      "source": [
        "path_LR_Bic_MC = './vsrnet_test_hr'\n",
        "path_HR = './vsrnet_test_hr'\n",
        "videos_h5_name = ['scene_40.h5']\n",
        "videos_h5_name.sort()"
      ],
      "metadata": {
        "id": "O3oQP1rrvc3z"
      },
      "execution_count": null,
      "outputs": [],
      "id": "O3oQP1rrvc3z"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Gcsux3vwZJq"
      },
      "outputs": [],
      "source": [
        "h5_len = len(videos_h5_name)\n",
        "model_PSNR   = np.zeros(h5_len)\n",
        "model_SSIM   = np.zeros(h5_len)\n",
        "bicubic_PSNR = np.zeros(h5_len)\n",
        "bicubic_SSIM = np.zeros(h5_len)\n",
        "model_time   = np.zeros(h5_len)"
      ],
      "id": "2Gcsux3vwZJq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8U3KtNhwawy"
      },
      "outputs": [],
      "source": [
        "out_path = './'\n",
        "if not os.path.exists(out_path):\n",
        "    os.makedirs(out_path)"
      ],
      "id": "J8U3KtNhwawy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iA009Ixi2RPw"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "import math\n",
        "\n",
        "def psnr(img1, img2):\n",
        "    mse = numpy.mean( (img1 - img2) ** 2 )\n",
        "    if mse == 0:\n",
        "        return 100\n",
        "    PIXEL_MAX = 255.0\n",
        "    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))"
      ],
      "id": "iA009Ixi2RPw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSlXCgjh2dRH"
      },
      "outputs": [],
      "source": [
        "from scipy.ndimage import gaussian_filter\n",
        "\n",
        "from numpy.lib.stride_tricks import as_strided as ast\n",
        "\n",
        "\"\"\"\n",
        "Hat tip: http://stackoverflow.com/a/5078155/1828289\n",
        "\"\"\"\n",
        "def block_view(A, block=(3, 3)):\n",
        "    \"\"\"Provide a 2D block view to 2D array. No error checking made.\n",
        "    Therefore meaningful (as implemented) only for blocks strictly\n",
        "    compatible with the shape of A.\"\"\"\n",
        "    # simple shape and strides computations may seem at first strange\n",
        "    # unless one is able to recognize the 'tuple additions' involved ;-)\n",
        "    shape = (A.shape[0]// block[0], A.shape[1]// block[1])+ block\n",
        "    strides = (block[0]* A.strides[0], block[1]* A.strides[1])+ A.strides\n",
        "    return ast(A, shape= shape, strides= strides)\n",
        "\n",
        "\n",
        "def ssim(img1, img2, C1=0.01**2, C2=0.03**2):\n",
        "\n",
        "    bimg1 = block_view(img1, (4,4))\n",
        "    bimg2 = block_view(img2, (4,4))\n",
        "    s1  = numpy.sum(bimg1, (-1, -2))\n",
        "    s2  = numpy.sum(bimg2, (-1, -2))\n",
        "    ss  = numpy.sum(bimg1*bimg1, (-1, -2)) + numpy.sum(bimg2*bimg2, (-1, -2))\n",
        "    s12 = numpy.sum(bimg1*bimg2, (-1, -2))\n",
        "\n",
        "    vari = ss - s1*s1 - s2*s2\n",
        "    covar = s12 - s1*s2\n",
        "\n",
        "    ssim_map =  (2*s1*s2 + C1) * (2*covar + C2) / ((s1*s1 + s2*s2 + C1) * (vari + C2))\n",
        "    return numpy.mean(ssim_map)\n",
        "\n",
        "# FIXME there seems to be a problem with this code\n",
        "def ssim_exact(img1, img2, sd=1.5, C1=0.01**2, C2=0.03**2):\n",
        "\n",
        "    mu1 = gaussian_filter(img1, sd)\n",
        "    mu2 = gaussian_filter(img2, sd)\n",
        "    mu1_sq = mu1 * mu1\n",
        "    mu2_sq = mu2 * mu2\n",
        "    mu1_mu2 = mu1 * mu2\n",
        "    sigma1_sq = gaussian_filter(img1 * img1, sd) - mu1_sq\n",
        "    sigma2_sq = gaussian_filter(img2 * img2, sd) - mu2_sq\n",
        "    sigma12 = gaussian_filter(img1 * img2, sd) - mu1_mu2\n",
        "\n",
        "    ssim_num = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2))\n",
        "\n",
        "    ssim_den = ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
        "\n",
        "    ssim_map = ssim_num / ssim_den\n",
        "    return numpy.mean(ssim_map)"
      ],
      "id": "wSlXCgjh2dRH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1L_fRCrVwhHv",
        "outputId": "b8cbd8f7-fdcc-4093-8e18-d66155dfa65f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14/14 [00:12<00:00,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===> Test on Video Idx: 0 Complete: Model PSNR: 38.3895 dB, Model SSIM: 0.9989 , Bicubic PSNR:  43.0632 dB, Bicubic SSIM: 0.9999 , Average time: 684.5226\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import cv2\n",
        "\n",
        "video_idx = 0\n",
        "#   Read h5 file\n",
        "LR_Bic_MC_h5_file = h5py.File('./vsrnet_test_lr', 'r')\n",
        "LR_Bic_MC_h5_data = LR_Bic_MC_h5_file['data']\n",
        "HR_h5_file = h5py.File('./vsrnet_test_hr', 'r')\n",
        "HR_h5_data = HR_h5_file['data']\n",
        "    \n",
        "# load to memory\n",
        "HR_h5_data = HR_h5_data[()]#.value\n",
        "LR_Bic_MC_h5_data = LR_Bic_MC_h5_data[()]#.value\n",
        "    \n",
        "# transpose to correct order\n",
        "HR_h5_data = np.transpose(HR_h5_data, (3, 2, 1, 0))\n",
        "LR_Bic_MC_h5_data = np.transpose(LR_Bic_MC_h5_data, (3, 2, 1, 0))\n",
        "    \n",
        "frame_number = LR_Bic_MC_h5_data.shape[0]\n",
        "\n",
        "IS_REAL_TIME = False\n",
        "\n",
        "video_name = 'scene_40_mse'\n",
        "    \n",
        "if not IS_REAL_TIME:\n",
        "    fps = 30\n",
        "    size = (LR_Bic_MC_h5_data.shape[3], LR_Bic_MC_h5_data.shape[2])\n",
        "    output_name = out_path + video_name.split('.')[0] + '.avi'\n",
        "    videoWriter = cv2.VideoWriter(output_name, cv2.VideoWriter_fourcc('M','J','P','G'), fps, size)\n",
        "#            videoWriter = cv2.VideoWriter(output_name, cv2.VideoWriter_fourcc(*'XVID'), fps, size)\n",
        "        \n",
        "#   Prepare to save PSNR and SSIM of the current video\n",
        "#   Each value corresponding to one test frame\n",
        "model_PSNR_cur   = np.zeros(frame_number)\n",
        "model_SSIM_cur   = np.zeros(frame_number)\n",
        "bicubic_PSNR_cur = np.zeros(frame_number)\n",
        "bicubic_SSIM_cur = np.zeros(frame_number)\n",
        "model_time_cur   = np.zeros(frame_number)\n",
        "    \n",
        "for idx in tqdm(range(0, frame_number)):\n",
        "    img_HR = HR_h5_data[idx, 0, :, :] #2D\n",
        "    img_LR_Bic_MC = LR_Bic_MC_h5_data[idx, :, :, :] #3D 5x1080x1920\n",
        "    \n",
        "    # Reshape to 4D\n",
        "    img_LR_Bic_MC = img_LR_Bic_MC.reshape((1, img_LR_Bic_MC.shape[0], img_LR_Bic_MC.shape[1], img_LR_Bic_MC.shape[2]))\n",
        "    \n",
        "    img_LR_Bic_MC = img_LR_Bic_MC.astype(np.float32)\n",
        "\n",
        "    img_LR_Bic_MC =  torch.from_numpy(img_LR_Bic_MC)\n",
        "                        \n",
        "    if torch.cuda.is_available():\n",
        "        img_LR_Bic_MC = img_LR_Bic_MC.cuda()\n",
        "\n",
        "    start = time.time()\n",
        "    if img_LR_Bic_MC.sum() != 0:\n",
        "        img_HR_net = model(img_LR_Bic_MC)\n",
        "\n",
        "    else:\n",
        "        img_HR_net = img_LR_Bic_MC[:,2,:,:]\n",
        "        img_HR_net = img_HR_net.reshape((1, 1, img_HR.shape[0], img_HR.shape[1])) # reshape to 1x1x1080x1920\n",
        "        \n",
        "    end = time.time() # measure the computation time\n",
        "    \n",
        "    img_HR_net = img_HR_net.cpu()\n",
        "    img_HR_net = img_HR_net.data[0].numpy()\n",
        "    img_HR_net *= 255.0\n",
        "    img_HR_net = img_HR_net.clip(0, 255)\n",
        "    img_HR_net = img_HR_net.astype(np.uint8)\n",
        "    \n",
        "    img_LR_Bic_MC = img_LR_Bic_MC.cpu()\n",
        "    img_LR_Bic = img_LR_Bic_MC[:, 2, :, :] # center frame\n",
        "    img_LR_Bic = img_LR_Bic.data[0].numpy()\n",
        "    img_LR_Bic *= 255.0\n",
        "    img_LR_Bic = img_LR_Bic.clip(0, 255)\n",
        "    img_LR_Bic = img_LR_Bic.astype(np.uint8)\n",
        "    \n",
        "    img_HR = img_HR.reshape((1, img_HR.shape[0], img_HR.shape[1]))\n",
        "    img_LR_Bic = img_LR_Bic.reshape((1, img_LR_Bic.shape[0], img_LR_Bic.shape[1]))\n",
        "  \n",
        "    model_PSNR_cur[idx]   = psnr((img_HR).reshape(img_HR.shape[1], img_HR.shape[2]).astype(int), (img_HR_net).reshape(img_HR_net.shape[1], img_HR_net.shape[2]).astype(int))\n",
        "    model_SSIM_cur[idx]   = ssim((img_HR).reshape(img_HR.shape[1], img_HR.shape[2]).astype(int), (img_HR_net).reshape(img_HR_net.shape[1], img_HR_net.shape[2]).astype(int))\n",
        "    bicubic_PSNR_cur[idx] = psnr((img_HR).reshape(img_HR.shape[1], img_HR.shape[2]).astype(int), (img_LR_Bic).reshape(img_LR_Bic.shape[1], img_LR_Bic.shape[2]).astype(int))\n",
        "    bicubic_SSIM_cur[idx] = ssim((img_HR).reshape(img_HR.shape[1], img_HR.shape[2]).astype(int), (img_LR_Bic).reshape(img_LR_Bic.shape[1], img_LR_Bic.shape[2]).astype(int))\n",
        "    model_time_cur[idx]   = (end-start)\n",
        "\n",
        "    # Repeat to 3 channels to save and display\n",
        "    img_HR_net = np.repeat(img_HR_net, 3, axis=0)\n",
        "    img_HR_net = np.transpose(img_HR_net, (1, 2, 0))\n",
        "\n",
        "    if IS_REAL_TIME:\n",
        "        plt.imshow(img_HR_net, cmap = 'gray')\n",
        "        plt.show()\n",
        "\n",
        "#                cv2.imshow('LR Video ', img_LR_Bic)\n",
        "#                cv2.imshow('SR Video ', img_HR_net)\n",
        "#                cv2.waitKey(DELAY_TIME)\n",
        "    else:\n",
        "        # save video\n",
        "        videoWriter.write(img_HR_net)\n",
        "    \n",
        "# Done video writing\n",
        "videoWriter.release()\n",
        "\n",
        "# Save PSNR and SSIM\n",
        "# Exclude PSNR = 100 cases (caused by black frames)\n",
        "cal_flag = (model_PSNR_cur != 100)\n",
        "model_PSNR[video_idx]   = np.mean(model_PSNR_cur[cal_flag])\n",
        "model_SSIM[video_idx]   = np.mean(model_SSIM_cur[cal_flag])\n",
        "bicubic_PSNR[video_idx] = np.mean(bicubic_PSNR_cur[cal_flag])\n",
        "bicubic_SSIM[video_idx] = np.mean(bicubic_SSIM_cur[cal_flag])\n",
        "model_time[video_idx]   = np.mean(model_time_cur[cal_flag])\n",
        "\n",
        "print(\"===> Test on Video Idx: \" + str(video_idx) +\" Complete: Model PSNR: {:.4f} dB, Model SSIM: {:.4f} , Bicubic PSNR:  {:.4f} dB, Bicubic SSIM: {:.4f} , Average time: {:.4f}\"\n",
        "  .format(model_PSNR[video_idx], model_SSIM[video_idx], bicubic_PSNR[video_idx], bicubic_SSIM[video_idx], model_time[video_idx]*1000))\n",
        "video_idx += 1"
      ],
      "id": "1L_fRCrVwhHv"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sP3KU2cPHkcQ"
      },
      "id": "sP3KU2cPHkcQ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}